{
 "cells": [
  {
   "cell_type": "raw",
   "id": "23017f05",
   "metadata": {},
   "source": [
    "Title: Logging for ML Model Deployments\n",
    "Date: 2023-04-20 12:00\n",
    "Category: Blog\n",
    "Slug: logging-for-ml-models\n",
    "Authors: Brian Schmidt\n",
    "Summary: As software systems become more and more complex, the people that build and operate these systems are finding that they are very hard to debug and inspect. To be able to solve this issue, a software system needs to be observable. An observable system is a system that allows an outside observer to infer the internal state of the system based purely on the data that it generates. The quality of \"observability\" helps the operators of a system to understand the inner workings of the system and to solve issues that may come up, even when the issues may be unprecedented. Just like any other software component, machine learning models need to create a log of events that may be useful later on. For example, we may want to know how many predictions the model made, how many errors occurred, and any other interesting events that we may want to keep track of. In this blog post we'll create a decorator that creates a log for a machine learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb9e777",
   "metadata": {},
   "source": [
    "# Logging for ML Model Deployments\n",
    "\n",
    "In previous blog posts we [introduced the decorator pattern](https://www.tekhnoal.com/ml-model-decorators.html) for ML model deployments and then showed how to use the pattern to build extensions for an ML model deployment. For example, in [this blog post](https://www.tekhnoal.com/data-enrichment-for-ml-models.html) we did data enrichment using a PostgreSQL database. The extensions were added without having to modify the machine learning model code at all, we were able to do it by using the decorator pattern. In this blog post we’ll add logging to a model deployment without having to modify the model code, using a decorator. \n",
    "\n",
    "This blog post is written in a Jupyter notebook and we'll be switching between Python code and shell commands, the formatting will reflect this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da0503f",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "As software systems become more and more complex, the people that build and operate these systems are finding that they are very hard to debug and inspect. To be able to solve this issue, a software system needs to be observable. An observable system is a system that allows an outside observer to infer the internal state of the system based purely on the data that it generates. The quality of \"observability\" helps the operators of a system to understand the inner workings of the system and to solve issues that may come up, even when the issues may be unprecedented.\n",
    "\n",
    "Observability is a non-functional requirement (NFR) of a system. An NFR is a requirement that is placed on the operation of a system that has nothing to do with the specific functions of the system. Rather, it is a cross-cutting concern that needs to be addressed within the whole system design. Logging is a way that we can implement observability in a software system. \n",
    "\n",
    "In the world of software systems, a \"log\" is a record of events that happen as software runs. A log is made up of individual records called log records that each represent a single event in the software system. Logs are useful for debugging the system, keeping a permanent record of its activities, and many other purposes. In general, log records are designed for debugging, alerting, and auditing the activities of the system.\n",
    "\n",
    "Just like any other software component, machine learning models need to create a log of events that may be useful later on. For example, we may want to know how many predictions the model made, how many errors occurred, and any other interesting events that we may want to keep track of. In this blog post we'll create a decorator that creates a log for a machine learning model.\n",
    "\n",
    "This post is not meant to be a full guide for doing logging in Python, but we'll include some background information to make it easier to understand. Logging in Python can get complicated and there are other places that cover it more thoroughly. [Here](https://realpython.com/python-logging/) is a good place to learn more about Python logging.\n",
    "\n",
    "All of the code is available in [this github repository](https://github.com/schmidtbri/logging-for-ml-models)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587187c1",
   "metadata": {},
   "source": [
    "## Software Architecture\n",
    "\n",
    "The logging decorator will operate within the model service, but it requires outside services to handle the logs that it produces. This makes the software architecture more complicated and requires that we add several more services to the mix. \n",
    "\n",
    "![Software Architecture](software_architecture_lfmlm.png)\n",
    "![Software Architecture]({attach}software_architecture_lfmlm.png){ width=100% }\n",
    "\n",
    "The logging decorator is executing right after the prediction request is received from the client and a prediction is made by the model, it will send logs to be handled by other services. The other services are:\n",
    "\n",
    "- Log Forwarder: a service that runs on each cluster node that forwards logs from the local hard drive to the log aggregator service.\n",
    "- Log Storage: a service that can store logs and also query them.\n",
    "- Log User Interface: a service with a web interface that provides access to the logs stored in the log storage service.\n",
    "\n",
    "The specific services that we'll use will be detailed later in the blog post."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2fbac3",
   "metadata": {},
   "source": [
    "## Logging Best Practices\n",
    "\n",
    "There are certain things that we can do when we create a log for our application that makes it more useful, especially in production settings. For example, attaching a \"level\" to each log record makes it easy to filter the log according to the severity of the events. For example, a log record is of level \"INFO\" when it communicates a simple action that the system has taken. A \"WARNING\" log event is an event that may indicate a problem in the system, but the system can continue to run. A good description of the common log levels is [here](https://sematext.com/blog/logging-levels/).\n",
    "\n",
    "Another good practice for logs is to include contextual information that can help to debug any problems that may arise in the execution of the code. For example, we can include the location in the codebase where the log record was generated. This information is very helpful during debugging and helps to quickly find the code that caused the event to happen. The information is often presented as the function name, code file name, and line number where the log record was generated. Another piece of useful contextual information is the hostname of the machine where the log was generated.\n",
    "\n",
    "Logs should be easy to interpret for both humans and machines, this means that log records  are often written in text strings. Humans can easily read text, but parsing a text string is complicated for machines. To allow both humans and machines to easily parse a log message, a good middle ground is to use JSON formatting. JSON-formatted logs are easy to parse, but also allow a human to quickly read and understand a log message.\n",
    "\n",
    "Unique identifiers are useful to include in logs because they allow us to correlate many different log records together into a cohesive picture. For example, a correlation id is a unique ID that is generated to identify a specific transaction or query in a system. Adding unique identifiers to each log record can make it possible to debug complex problems that happen across system boundaries. A good description of correlation ids is [here](https://hilton.org.uk/blog/microservices-correlation-id)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19c74e0",
   "metadata": {},
   "source": [
    "## Logging in Python\n",
    "\n",
    "The python standard library has a module that can simplify logging. The logging module is imported and used like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2c4469f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T03:16:42.552149Z",
     "start_time": "2023-11-18T03:16:41.478273Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "\n",
    "logger.warning(\"Warning message.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a3efbe",
   "metadata": {},
   "source": [
    "To start logging, we instantiated a logger object using the logging.getLogger() function. Then we used the logger object to log a WARNING message.\n",
    "\n",
    "The log records are being sent to the stderr output of the process by default. We'll change that by instantiating a StreamHandler and pointing it at the stdout stream:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0718fa1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T03:16:43.225820Z",
     "start_time": "2023-11-18T03:16:41.484435Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning message.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "stream_handler = logging.StreamHandler(sys.stdout)\n",
    "\n",
    "logger.addHandler(stream_handler)\n",
    "logger.warning(\"Warning message.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4192a9",
   "metadata": {},
   "source": [
    "We just replaced the original log handler that logged messages to stderror with another one that logs to stdout. A log handler is a software component that is able to send log messages to destinations outside of the running process.\n",
    "\n",
    "We can also log messages at other levels, here is a WARNING and DEBUG message:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d87c502e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T03:16:43.241170Z",
     "start_time": "2023-11-18T03:16:41.498665Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning message.\n"
     ]
    }
   ],
   "source": [
    "logger.warning(\"Warning message.\")\n",
    "logger.debug(\"Debug message.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76e2b34",
   "metadata": {},
   "source": [
    "When the code above executed, only the WARNING message was printed because the logger only sends log messages to the output that are at the WARNING level or above by default. This filtering functionality is helpful when you are only interested in logs above a certain level. We can change that by configuring the logger:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b301d8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T03:16:43.258587Z",
     "start_time": "2023-11-18T03:16:41.512268Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning message.\n",
      "Debug message.\n"
     ]
    }
   ],
   "source": [
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "logger.warning(\"Warning message.\")\n",
    "logger.debug(\"Debug message.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4698dcbd",
   "metadata": {},
   "source": [
    "Now we can see the debug message. \n",
    "\n",
    "We can put in more information to the log record by adding a formatter to the log handler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c708ca81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T03:16:43.265242Z",
     "start_time": "2023-11-18T03:16:41.521493Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-18 14:45:39,589:root:WARNING: Warning message.\n",
      "2023-11-18 14:45:39,589:root:DEBUG: Debug message.\n"
     ]
    }
   ],
   "source": [
    "formatter = logging.Formatter('%(asctime)s:%(name)s:%(levelname)s: %(message)s')\n",
    "stream_handler.setFormatter(formatter)\n",
    "\n",
    "logger.warning(\"Warning message.\")\n",
    "logger.debug(\"Debug message.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5b381a",
   "metadata": {},
   "source": [
    "A formatter is a software component that can format log messages according to a desired format. The log record now contains the date and time of the event, the name of the logger that generated the message, the level of the log, and the log message. These are all standard fields that are attached to log messages when they are created, more information about these fields can be found in the Python documentation [here](https://docs.python.org/3/library/logging.html#logrecord-attributes).\n",
    "\n",
    "Each logger has a name attached to it when it is created, the name of the current logger is \"root\" because we created the logger without specifying a name. We can create a new logger with a name like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b55baffd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T03:16:43.272442Z",
     "start_time": "2023-11-18T03:16:41.531436Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-18 14:45:39,592:test_logger:DEBUG: Debug message.\n"
     ]
    }
   ],
   "source": [
    "logger = logging.getLogger(\"test_logger\")\n",
    "\n",
    "logger.debug(\"Debug message.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4c8b04",
   "metadata": {},
   "source": [
    "The log record has the name of the logger, which is not the root logger that we were using before."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa766a6c",
   "metadata": {},
   "source": [
    "### Logging Environment Variables\n",
    "\n",
    "To log extra information that is not available by default within each log record we have to extend the logging module by creating Filter classes. A Filter is simply a class that filters log records and can also modify them. This information will come from the environment variables of the process in which the logger is running. \n",
    "\n",
    "To do this we'll create a Filter that is able to pick up information from the environment variables and add it to each log record. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6551ff93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T03:16:43.279558Z",
     "start_time": "2023-11-18T03:16:41.550265Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List\n",
    "from logging import Filter\n",
    "\n",
    "\n",
    "class EnvironmentInfoFilter(Filter):\n",
    "    \"\"\"Logging filter that adds information to log records from environment variables.\"\"\"\n",
    "    \n",
    "    def __init__(self, env_variables: List[str]):\n",
    "        super().__init__()\n",
    "        self._env_variables = env_variables\n",
    "\n",
    "    def filter(self, record):\n",
    "        for env_variable in self._env_variables:\n",
    "            record.__setattr__(env_variable.lower(), os.environ.get(env_variable, \"N/A\"))\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab13352e",
   "metadata": {},
   "source": [
    "To try it out we'll have to add an environment variable that will be logged:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60011af0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T03:16:43.286072Z",
     "start_time": "2023-11-18T03:16:41.558702Z"
    }
   },
   "outputs": [],
   "source": [
    "os.environ[\"NODE_IP\"] = \"198.197.196.195\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3ac84b",
   "metadata": {},
   "source": [
    "Next, we'll instantiate the Filter class and add it to a logger instance to see how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ced21823",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T03:16:43.300752Z",
     "start_time": "2023-11-18T03:16:41.567766Z"
    }
   },
   "outputs": [],
   "source": [
    "environment_info_filter = EnvironmentInfoFilter(env_variables=[\"NODE_IP\"])\n",
    "\n",
    "logger.addFilter(environment_info_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "475fabb6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T03:16:43.301591Z",
     "start_time": "2023-11-18T03:16:41.569888Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-18 14:45:39,603 : test_logger : WARNING : 198.197.196.195 : Warning message.\n",
      "2023-11-18 14:45:39,604 : test_logger : DEBUG : 198.197.196.195 : Debug message.\n"
     ]
    }
   ],
   "source": [
    "formatter = logging.Formatter('%(asctime)s : %(name)s : %(levelname)s : %(node_ip)s : %(message)s')\n",
    "stream_handler.setFormatter(formatter)\n",
    "\n",
    "logger.warning(\"Warning message.\")\n",
    "logger.debug(\"Debug message.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a644cd2e",
   "metadata": {},
   "source": [
    "The log record now contains the IP address that we set in the environment variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae437b1",
   "metadata": {},
   "source": [
    "### Logging in JSON\n",
    "\n",
    "So far, the logs we've been generated have been in a slightly structured format that we came up with. It uses colons to separate out different sections of the log record. If we want to easily parse the logs to extract information from them, we should instead use JSON records. In this section we'll use the python-json-logger package to format the log records as JSON strings. \n",
    "\n",
    "First, we'll install the package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d365f7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "!pip install python-json-logger\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476ab922",
   "metadata": {},
   "source": [
    "We'll instantiate a JsonFormatter object that will convert the logs to JSON:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7015f68e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T03:16:43.390382Z",
     "start_time": "2023-11-18T03:16:41.702515Z"
    }
   },
   "outputs": [],
   "source": [
    "from pythonjsonlogger import jsonlogger\n",
    "\n",
    "\n",
    "json_formatter = jsonlogger.JsonFormatter(\"%(asctime)s %(name)s %(levelname)s %(node_ip)s %(message)s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983cae09",
   "metadata": {},
   "source": [
    "We'll add the formatter to the stream handler that we created above like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2029c382",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T03:16:43.390514Z",
     "start_time": "2023-11-18T03:16:41.706115Z"
    }
   },
   "outputs": [],
   "source": [
    "stream_handler.setFormatter(json_formatter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887f822b",
   "metadata": {},
   "source": [
    "Now when we log, the output will be a JSON string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "205fc603",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T03:16:43.390660Z",
     "start_time": "2023-11-18T03:16:41.708600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"asctime\": \"2023-11-18 14:45:40,408\", \"name\": \"test_logger\", \"levelname\": \"ERROR\", \"node_ip\": \"198.197.196.195\", \"message\": \"Error message.\"}\n"
     ]
    }
   ],
   "source": [
    "logger.error(\"Error message.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe7f3c9",
   "metadata": {},
   "source": [
    "We can add easily add more fields from the log record to make it more comprehensive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f33d3e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T03:16:43.397853Z",
     "start_time": "2023-11-18T03:16:41.711033Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"asctime\": \"2023-11-18 14:45:40,411\", \"node_ip\": \"198.197.196.195\", \"process\": 24298, \"thread\": 8379588736, \"pathname\": \"/var/folders/w2/86604rs93fq7v_lyr6xl7x3m0000gn/T/ipykernel_24298/2505421541.py\", \"lineno\": 5, \"levelname\": \"ERROR\", \"message\": \"Error message.\"}\n"
     ]
    }
   ],
   "source": [
    "json_formatter = jsonlogger.JsonFormatter(\"%(asctime)s %(node_ip)s %(process)s %(thread)s %(pathname)s %(lineno)s %(levelname)s %(message)s\")\n",
    "\n",
    "stream_handler.setFormatter(json_formatter)\n",
    "\n",
    "logger.error(\"Error message.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31a35a1",
   "metadata": {},
   "source": [
    "Some of these fields were added by the Filter that we built above, other fields are [default fields](https://docs.python.org/3/library/logging.html#logrecord-attributes) provided by the Python logging module.\n",
    "\n",
    "The JSON formatter can also add extra fields and values to the log record by using the \"extra\" parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b93a7a34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T03:16:43.398004Z",
     "start_time": "2023-11-18T03:16:41.713260Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"asctime\": \"2023-11-18 14:45:40,414\", \"node_ip\": \"198.197.196.195\", \"process\": 24298, \"thread\": 8379588736, \"pathname\": \"/var/folders/w2/86604rs93fq7v_lyr6xl7x3m0000gn/T/ipykernel_24298/1433050719.py\", \"lineno\": 9, \"levelname\": \"ERROR\", \"message\": \"message\", \"action\": \"predict\", \"model_qualified_name\": \"model_qualified_name\", \"model_version\": \"model_version\", \"status\": \"error\", \"error_info\": \"error_info\"}\n"
     ]
    }
   ],
   "source": [
    "extra = {\n",
    "    \"action\": \"predict\",\n",
    "    \"model_qualified_name\": \"model_qualified_name\",\n",
    "    \"model_version\": \"model_version\",\n",
    "    \"status\":\"error\",\n",
    "    \"error_info\": \"error_info\"\n",
    "}\n",
    "\n",
    "logger.error(\"message\", extra=extra)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c722888a",
   "metadata": {},
   "source": [
    "The extra fields are:\n",
    "\n",
    "- action: the method called on the MLModel instance\n",
    "- model_qualified_name: the qualified name of the model\n",
    "- model_version: the version of the model\n",
    "- status: whether the action succeeded or not, can be \"success\" or \"error\"\n",
    "- error_info: extra error information, only present if an error occurred\n",
    "\n",
    "This information would normally be included in the \"message\" field of the log record as unstructured text, but by breaking it out and putting it into individual fields in the JSON log record we'll be able to parse it later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c740a147",
   "metadata": {},
   "source": [
    "### Putting It All Together\n",
    "\n",
    "We've done a few things with the logger module, now we need to put it all together into one configuration that we can use to set up the logger the way we want it.\n",
    "\n",
    "The logging.config.dictConfig() function can accept all of the options of the loggers, formatters, handlers, and filters and set them up with one function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d801277",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T03:16:43.398057Z",
     "start_time": "2023-11-18T03:16:41.716268Z"
    }
   },
   "outputs": [],
   "source": [
    "import logging.config\n",
    "\n",
    "\n",
    "logging_config = {\n",
    "    \"version\": 1,\n",
    "    \"disable_existing_loggers\": True,\n",
    "    \"loggers\": {\n",
    "        \"root\": {\n",
    "            \"level\": \"INFO\",\n",
    "            \"handlers\": [\"stdout\"],\n",
    "            \"propagate\": False\n",
    "        }\n",
    "    },\n",
    "    \"filters\": {\n",
    "        \"environment_info_filter\": {\n",
    "            \"()\": \"__main__.EnvironmentInfoFilter\",\n",
    "            \"env_variables\": [\"NODE_IP\"]\n",
    "        }\n",
    "    },\n",
    "    \"formatters\": {\n",
    "        \"json_formatter\": {\n",
    "            \"class\": \"pythonjsonlogger.jsonlogger.JsonFormatter\",\n",
    "            \"format\": \"%(asctime)s %(node_ip)s %(name)s %(pathname)s %(lineno)s %(levelname)s %(message)s\"\n",
    "        }\n",
    "    },\n",
    "    \"handlers\": {\n",
    "        \"stdout\":{\n",
    "            \"level\":\"INFO\",\n",
    "            \"class\":\"logging.StreamHandler\",\n",
    "            \"stream\": \"ext://sys.stdout\",\n",
    "            \"formatter\": \"json_formatter\",\n",
    "            \"filters\": [\"environment_info_filter\"]\n",
    "        }\n",
    "    }    \n",
    "}\n",
    "\n",
    "logging.config.dictConfig(logging_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "674b3a5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T03:16:43.398208Z",
     "start_time": "2023-11-18T03:16:41.718418Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"asctime\": \"2023-11-18 14:45:40,420\", \"node_ip\": \"198.197.196.195\", \"name\": \"root\", \"pathname\": \"/var/folders/w2/86604rs93fq7v_lyr6xl7x3m0000gn/T/ipykernel_24298/4067465749.py\", \"lineno\": 4, \"levelname\": \"INFO\", \"message\": \"Info message.\"}\n",
      "{\"asctime\": \"2023-11-18 14:45:40,421\", \"node_ip\": \"198.197.196.195\", \"name\": \"root\", \"pathname\": \"/var/folders/w2/86604rs93fq7v_lyr6xl7x3m0000gn/T/ipykernel_24298/4067465749.py\", \"lineno\": 5, \"levelname\": \"ERROR\", \"message\": \"Error message.\"}\n"
     ]
    }
   ],
   "source": [
    "logger = logging.getLogger()\n",
    "\n",
    "logger.debug(\"Debug message.\")\n",
    "logger.info(\"Info message.\")\n",
    "logger.error(\"Error message.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8377be12",
   "metadata": {},
   "source": [
    "The logger behaved in the same way as when we created it programmatically."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458ccd2e",
   "metadata": {},
   "source": [
    "## Installing a Model\n",
    "\n",
    "We won't be training an ML model from scratch in this blog post because it would take a lot of space in the post. We'll be reusing a model that we built in a [previous blog post](https://www.tekhnoal.com/health-checks-for-ml-model-deployments.html). The model's code is hosted in [this github repository](https://github.com/schmidtbri/health-checks-for-ml-model-deployments). The model is used to predict credit risk.\n",
    "\n",
    "The model itself can be installed as a normal Python package, using the pip command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bce98912",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T03:16:44.861470Z",
     "start_time": "2023-11-18T03:16:41.720957Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining insurance_charges_model from git+https://github.com/uqam-lomagnin/regression_model_socratis01_fixed#egg=insurance_charges_model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Updating ./src/insurance-charges-model clone\n",
      "  Running command git fetch -q --tags\n",
      "  Running command git reset --hard -q 07482f6e5d7eb004d013b17a763b69e3cf6e92dc\n",
      "  Preparing metadata (setup.py) ... \u001B[?25ldone\n",
      "\u001B[?25hRequirement already satisfied: ml-base>=0.1.0 in /Users/seydina/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from insurance_charges_model) (0.2.2)\n",
      "Requirement already satisfied: rest_model_service>=0.1.0 in /Users/seydina/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from insurance_charges_model) (0.5.1)\n",
      "Requirement already satisfied: pandas in /Users/seydina/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from insurance_charges_model) (1.5.3)\n",
      "Requirement already satisfied: scikit-learn==1.3.2 in /Users/seydina/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from insurance_charges_model) (1.3.2)\n",
      "Requirement already satisfied: featuretools==0.24.0 in /Users/seydina/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from insurance_charges_model) (0.24.0)\n",
      "Requirement already satisfied: tpot==0.11.7 in /Users/seydina/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from insurance_charges_model) (0.11.7)\n",
      "Requirement already satisfied: scipy>=0.13.3 in /Users/seydina/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from featuretools==0.24.0->insurance_charges_model) (1.11.3)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /Users/seydina/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from featuretools==0.24.0->insurance_charges_model) (1.26.2)\n",
      "Requirement already satisfied: tqdm>=4.32.0 in /Users/seydina/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from featuretools==0.24.0->insurance_charges_model) (4.66.1)\n",
      "Requirement already satisfied: pyyaml>=3.12 in /Users/seydina/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from featuretools==0.24.0->insurance_charges_model) (6.0.1)\n",
      "Requirement already satisfied: cloudpickle>=0.4.0 in /Users/seydina/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from featuretools==0.24.0->insurance_charges_model) (3.0.0)\n",
      "Requirement already satisfied: distributed>=2.12.0 in /Users/seydina/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from featuretools==0.24.0->insurance_charges_model) (2023.11.0)\n",
      "Requirement already satisfied: dask[dataframe]>=2.12.0 in /Users/seydina/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from featuretools==0.24.0->insurance_charges_model) (2023.11.0)\n",
      "Requirement already satisfied: psutil>=5.4.8 in /Users/seydina/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from featuretools==0.24.0->insurance_charges_model) (5.9.6)\n",
      "Requirement already satisfied: click>=7.0.0 in /Users/seydina/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from featuretools==0.24.0->insurance_charges_model) (8.1.7)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/seydina/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from scikit-learn==1.3.2->insurance_charges_model) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/seydina/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from scikit-learn==1.3.2->insurance_charges_model) (3.2.0)\n",
      "Requirement already satisfied: deap>=1.2 in /Users/seydina/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from tpot==0.11.7->insurance_charges_model) (1.4.1)\n",
      "Requirement already satisfied: update-checker>=0.16 in /Users/seydina/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from tpot==0.11.7->insurance_charges_model) (0.18.0)\n",
      "Requirement already satisfied: stopit>=1.1.1 in /Users/seydina/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from tpot==0.11.7->insurance_charges_model) (1.1.2)\n",
      "Requirement already satisfied: xgboost>=1.1.0 in /Users/seydina/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from tpot==0.11.7->insurance_charges_model) (2.0.2)\n",
      "Requirement already satisfied: pydantic>=1.5 in /Users/seydina/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from ml-base>=0.1.0->insurance_charges_model) (2.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/seydina/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from pandas->insurance_charges_model) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/seydina/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from pandas->insurance_charges_model) (2023.3.post1)\n",
      "Requirement already satisfied: fastapi in /Users/seydina/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from rest_model_service>=0.1.0->insurance_charges_model) (0.104.1)\n",
      "Requirement already satisfied: uvicorn in /Users/seydina/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from rest_model_service>=0.1.0->insurance_charges_model) (0.24.0.post1)\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in /Users/seydina/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from dask[dataframe]>=2.12.0->featuretools==0.24.0->insurance_charges_model) (2023.10.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/seydina/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from dask[dataframe]>=2.12.0->featuretools==0.24.0->insurance_charges_model) (23.2)\n",
      "Requirement already satisfied: partd>=1.2.0 in /Users/seydina/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from dask[dataframe]>=2.12.0->featuretools==0.24.0->insurance_charges_model) (1.4.1)\n",
      "Requirement already satisfied: toolz>=0.10.0 in /Users/seydina/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from dask[dataframe]>=2.12.0->featuretools==0.24.0->insurance_charges_model) (0.12.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.13.0 in /Users/seydina/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from dask[dataframe]>=2.12.0->featuretools==0.24.0->insurance_charges_model) (6.8.0)\n",
      "Requirement already satisfied: jinja2>=2.10.3 in /Users/seydina/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from distributed>=2.12.0->featuretools==0.24.0->insurance_charges_model) (3.1.2)\n",
      "Requirement already satisfied: locket>=1.0.0 in /Users/seydina/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from distributed>=2.12.0->featuretools==0.24.0->insurance_charges_model) (1.0.0)\n",
      "Requirement already satisfied: msgpack>=1.0.0 in /Users/seydina/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from distributed>=2.12.0->featuretools==0.24.0->insurance_charges_model) (1.0.7)\n",
      "Requirement already satisfied: sortedcontainers>=2.0.5 in /Users/seydina/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from distributed>=2.12.0->featuretools==0.24.0->insurance_charges_model) (2.4.0)\n",
      "Requirement already satisfied: tblib>=1.6.0 in /Users/seydina/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from distributed>=2.12.0->featuretools==0.24.0->insurance_charges_model) (3.0.0)\n",
      "Requirement already satisfied: tornado>=6.0.4 in /Users/seydina/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from distributed>=2.12.0->featuretools==0.24.0->insurance_charges_model) (6.3.3)\n",
      "Requirement already satisfied: urllib3>=1.24.3 in /Users/seydina/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from distributed>=2.12.0->featuretools==0.24.0->insurance_charges_model) (2.1.0)\n",
      "Requirement already satisfied: zict>=3.0.0 in /Users/seydina/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from distributed>=2.12.0->featuretools==0.24.0->insurance_charges_model) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/seydina/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from pydantic>=1.5->ml-base>=0.1.0->insurance_charges_model) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.3 in /Users/seydina/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from pydantic>=1.5->ml-base>=0.1.0->insurance_charges_model) (2.14.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/seydina/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from pydantic>=1.5->ml-base>=0.1.0->insurance_charges_model) (4.8.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/seydina/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from python-dateutil>=2.8.1->pandas->insurance_charges_model) (1.16.0)\n",
      "Requirement already satisfied: requests>=2.3.0 in /Users/seydina/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from update-checker>=0.16->tpot==0.11.7->insurance_charges_model) (2.31.0)\n",
      "Requirement already satisfied: anyio<4.0.0,>=3.7.1 in /Users/seydina/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from fastapi->rest_model_service>=0.1.0->insurance_charges_model) (3.7.1)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /Users/seydina/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from fastapi->rest_model_service>=0.1.0->insurance_charges_model) (0.27.0)\n",
      "Requirement already satisfied: h11>=0.8 in /Users/seydina/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from uvicorn->rest_model_service>=0.1.0->insurance_charges_model) (0.14.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/seydina/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from anyio<4.0.0,>=3.7.1->fastapi->rest_model_service>=0.1.0->insurance_charges_model) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/seydina/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from anyio<4.0.0,>=3.7.1->fastapi->rest_model_service>=0.1.0->insurance_charges_model) (1.3.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/seydina/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from importlib-metadata>=4.13.0->dask[dataframe]>=2.12.0->featuretools==0.24.0->insurance_charges_model) (3.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/seydina/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from jinja2>=2.10.3->distributed>=2.12.0->featuretools==0.24.0->insurance_charges_model) (2.1.3)\n",
      "^C\n",
      "\u001B[31mERROR: Operation cancelled by user\u001B[0m\u001B[31m\n",
      "\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip available: \u001B[0m\u001B[31;49m22.3\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.3.1\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install -e git+https://github.com/uqam-lomagnin/regression_model_socratis01_fixed#egg=insurance_charges_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bfaeda",
   "metadata": {},
   "source": [
    "Making a prediction with the model is done through the CreditRiskModel class, which we'll import like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a33f646",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T03:16:45.979641Z",
     "start_time": "2023-11-18T03:16:44.863287Z"
    }
   },
   "outputs": [],
   "source": [
    "import insurance_charges_model\n",
    "from insurance_charges_model.prediction.model import InsuranceChargesModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0059299e",
   "metadata": {},
   "source": [
    "Now we'll instantiate the model class in order to make a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86688515",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T03:16:48.530440Z",
     "start_time": "2023-11-18T03:16:45.979873Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.\n",
      "  warnings.warn(\"Warning: optional dependency `torch` is not available. - skipping import of NN models.\")\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [22:16:48] WARNING: /Users/runner/work/xgboost/xgboost/src/gbm/../common/error_msg.h:80: If you are loading a serialized model (like pickle in Python, RDS in R) or\n",
      "configuration generated by an older version of XGBoost, please export the model by calling\n",
      "`Booster.save_model` from that version first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/stable/tutorials/saving_model.html\n",
      "\n",
      "for more details about differences between saving model and serializing.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "model = InsuranceChargesModel()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3476400c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f42d11f3",
   "metadata": {},
   "source": [
    "In order to make a prediction with the model instance, we'll need to instantiate the input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6c215e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T03:16:48.534589Z",
     "start_time": "2023-11-18T03:16:48.531131Z"
    }
   },
   "outputs": [],
   "source": [
    "from insurance_charges_model.prediction.schemas import InsuranceChargesModelInput,SexEnum,RegionEnum\n",
    "\n",
    "model_input = InsuranceChargesModelInput(\n",
    "    age=53, \n",
    "    sex= SexEnum.male, \n",
    "    bmi=15, \n",
    "    children=4, \n",
    "    smoker=True, \n",
    "    region=RegionEnum.southwest,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee29a143",
   "metadata": {},
   "source": [
    "The model's input schema is called CreditRiskModelInput and it holds all of the features required by the model to make a prediction.\n",
    "\n",
    "Now we can make a prediction with the model by calling the predict() method with an instance of the CreditRiskModelInput class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e880f111",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T03:16:48.584358Z",
     "start_time": "2023-11-18T03:16:48.535199Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InsuranceChargesModelOutput(charges=20949.85)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.predict(model_input)\n",
    "\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e87fd91",
   "metadata": {},
   "source": [
    "The model predicts that the client's risk is safe.\n",
    "\n",
    "The output is also provided as an object, and because the model is a classification model, the output is an Enum. We can view the schema of the model output by requesting the JSON schema from the object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16c1df0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T03:16:48.604433Z",
     "start_time": "2023-11-18T03:16:48.583761Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w2/86604rs93fq7v_lyr6xl7x3m0000gn/T/ipykernel_17948/1565345565.py:1: PydanticDeprecatedSince20: The `schema` method is deprecated; use `model_json_schema` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  model.output_schema.schema()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'description': \"Schema for output of the model's predict method.\",\n",
       " 'properties': {'charges': {'default': None,\n",
       "   'description': 'Individual medical costs billed by health insurance to customer in US dollars.',\n",
       "   'title': 'Charges',\n",
       "   'type': 'number'}},\n",
       " 'title': 'InsuranceChargesModelOutput',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output_schema.schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4df0a4",
   "metadata": {},
   "source": [
    "The two possible outputs of the model are \"safe\" and \"risky\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f628402f",
   "metadata": {},
   "source": [
    "## Creating the Logging Decorator\n",
    "\n",
    "As you saw above, the model did not produce any logs. To be able to emit some logs about the model's activity, we'll create a Decorator that will do logging around an MLModel instance. \n",
    "\n",
    "In order to build a MLModel decorator class, we'll need to inherit from the MLModelDecorator class and add some functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49868b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T03:16:48.604621Z",
     "start_time": "2023-11-18T03:16:48.590880Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "import logging\n",
    "from ml_base.decorator import MLModelDecorator\n",
    "from ml_base.ml_model import MLModelSchemaValidationException\n",
    "\n",
    "\n",
    "class LoggingDecorator(MLModelDecorator):\n",
    "    \"\"\"Decorator to do logging around an MLModel instance.\"\"\"\n",
    "\n",
    "    def __init__(self, input_fields: Optional[List[str]] = None, \n",
    "                 output_fields: Optional[List[str]] = None) -> None:\n",
    "        super().__init__(input_fields=input_fields, output_fields=output_fields)\n",
    "        self.__dict__[\"_logger\"] = None\n",
    "        \n",
    "    def predict(self, data):\n",
    "        if self.__dict__[\"_logger\"] is None:\n",
    "            self.__dict__[\"_logger\"] = logging.getLogger(\"{}_{}\".format(\n",
    "                self._model.qualified_name, \"logger\"))\n",
    "        \n",
    "        # extra fields to be added to the log record\n",
    "        extra = {\n",
    "            \"action\": \"predict\",\n",
    "            \"model_qualified_name\": self._model.qualified_name,\n",
    "            \"model_version\": self._model.version\n",
    "        }\n",
    "        \n",
    "        # adding model input fields to the extra fields to be logged\n",
    "        new_extra = dict(extra)\n",
    "        if self._configuration[\"input_fields\"] is not None:\n",
    "            for input_field in self._configuration[\"input_fields\"]:\n",
    "                new_extra[input_field] = getattr(data, input_field)\n",
    "        \n",
    "        self.__dict__[\"_logger\"].info(\"Prediction requested.\", extra=new_extra)\n",
    "        \n",
    "        try:\n",
    "            prediction = self._model.predict(data=data)\n",
    "            extra[\"status\"] = \"success\"\n",
    "            \n",
    "            # adding model output fields to the extra fields to be logged\n",
    "            new_extra = dict(extra)\n",
    "            if self._configuration[\"output_fields\"] is not None:\n",
    "                for output_field in self._configuration[\"output_fields\"]:\n",
    "                    new_extra[output_field] = getattr(prediction, output_field)            \n",
    "            self.__dict__[\"_logger\"].info(\"Prediction created.\", extra=new_extra) \n",
    "            return prediction\n",
    "        except Exception as e:\n",
    "            extra[\"status\"] = \"error\"\n",
    "            extra[\"error_info\"] = str(e)\n",
    "            self.__dict__[\"_logger\"].error(\"Prediction exception.\", extra=extra)\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b35205",
   "metadata": {},
   "source": [
    "The LoggingDecorator class has most of its logic in the predict() method. This method simply instantiates a logger object and logs a message before a prediction is made, after it is made, and in the case when an exception is raised. Notice that the exception information is logged, but the exception is re-raised immediately after. We don't want to keep the exception from being handled by whatever code is using the model, we just need to emit a log of the event.\n",
    "\n",
    "The decorator also adds a few fields to the log message:\n",
    "\n",
    "- action: the action that the model is performing, in this case \"prediction\"\n",
    "- model_qualified_name: the qualified name of the model performing the action\n",
    "- model_version: the version of the model performing the action\n",
    "- status: the result of the action, can be either \"success\" or \"error\"\n",
    "- error_info: an optional field that adds error information when an exception is raised\n",
    "\n",
    "These fields are added on top of all the regular fields that the logging package provides. The extra information should allow us to easily filter logs later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c60f1e3",
   "metadata": {},
   "source": [
    "## Decorating the Model\n",
    "\n",
    "To test out the decorator we’ll first instantiate the model object that we want to use with the decorator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6d2aac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T03:16:48.684624Z",
     "start_time": "2023-11-18T03:16:48.593070Z"
    }
   },
   "outputs": [],
   "source": [
    "model = InsuranceChargesModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401461a9",
   "metadata": {},
   "source": [
    "Next, we’ll instantiate the decorator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd1d76c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T03:16:48.693359Z",
     "start_time": "2023-11-18T03:16:48.609836Z"
    }
   },
   "outputs": [],
   "source": [
    "logging_decorator = LoggingDecorator()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5950edc",
   "metadata": {},
   "source": [
    "We can add the model instance to the decorator after it’s been instantiated like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fdd373",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T03:16:48.693504Z",
     "start_time": "2023-11-18T03:16:48.612997Z"
    }
   },
   "outputs": [],
   "source": [
    "decorated_model = logging_decorator.set_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc37bd0",
   "metadata": {},
   "source": [
    "We can see the decorator and the model objects by printing the reference to the decorator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2463acfd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T03:16:48.693699Z",
     "start_time": "2023-11-18T03:16:48.615625Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LoggingDecorator(InsuranceChargesModel)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decorated_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9caa907e",
   "metadata": {},
   "source": [
    "The decorator object is printing out its own type along with the type of the model that it is decorating.\n",
    "\n",
    "Now we can try out the logging decorator by making a prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80c4713",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T03:16:48.694229Z",
     "start_time": "2023-11-18T03:16:48.618035Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"asctime\": \"2023-11-17 22:16:48,617\", \"node_ip\": \"198.197.196.195\", \"name\": \"insurance_charges_model_logger\", \"pathname\": \"/var/folders/w2/86604rs93fq7v_lyr6xl7x3m0000gn/T/ipykernel_17948/668393871.py\", \"lineno\": 33, \"levelname\": \"INFO\", \"message\": \"Prediction requested.\", \"action\": \"predict\", \"model_qualified_name\": \"insurance_charges_model\", \"model_version\": \"0.1.0\"}\n",
      "{\"asctime\": \"2023-11-17 22:16:48,632\", \"node_ip\": \"198.197.196.195\", \"name\": \"insurance_charges_model_logger\", \"pathname\": \"/var/folders/w2/86604rs93fq7v_lyr6xl7x3m0000gn/T/ipykernel_17948/668393871.py\", \"lineno\": 44, \"levelname\": \"INFO\", \"message\": \"Prediction created.\", \"action\": \"predict\", \"model_qualified_name\": \"insurance_charges_model\", \"model_version\": \"0.1.0\", \"status\": \"success\"}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "InsuranceChargesModelOutput(charges=20949.85)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = decorated_model.predict(model_input)\n",
    "\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674d14a7",
   "metadata": {},
   "source": [
    "Calling the predict() method on the decorated model now emits two log messages. The first message is a \"Prediction requested.\" message and happens before the model's predict method is called. The second is a \"Prediction created.\" message and happens after the prediction is returned by the model to the decorator. The decorator can also log exceptions made by the model.\n",
    "\n",
    "The logging decorator is also able to grab fields from the model's input and output and log those alongside the other fields. Here is how to configure the logging decorator to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0573e03f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T03:16:48.694704Z",
     "start_time": "2023-11-18T03:16:48.636359Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"asctime\": \"2023-11-17 22:16:48,635\", \"node_ip\": \"198.197.196.195\", \"name\": \"insurance_charges_model_logger\", \"pathname\": \"/var/folders/w2/86604rs93fq7v_lyr6xl7x3m0000gn/T/ipykernel_17948/668393871.py\", \"lineno\": 33, \"levelname\": \"INFO\", \"message\": \"Prediction requested.\", \"action\": \"predict\", \"model_qualified_name\": \"insurance_charges_model\", \"model_version\": \"0.1.0\", \"age\": 53, \"sex\": \"male\"}\n",
      "{\"asctime\": \"2023-11-17 22:16:48,647\", \"node_ip\": \"198.197.196.195\", \"name\": \"insurance_charges_model_logger\", \"pathname\": \"/var/folders/w2/86604rs93fq7v_lyr6xl7x3m0000gn/T/ipykernel_17948/668393871.py\", \"lineno\": 44, \"levelname\": \"INFO\", \"message\": \"Prediction created.\", \"action\": \"predict\", \"model_qualified_name\": \"insurance_charges_model\", \"model_version\": \"0.1.0\", \"status\": \"success\", \"charges\": 20949.85}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "InsuranceChargesModelOutput(charges=20949.85)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logging_decorator = LoggingDecorator(input_fields=[\"age\", \"sex\"],\n",
    "                                     output_fields=[\"charges\"])\n",
    "\n",
    "decorated_model = logging_decorator.set_model(model)\n",
    "\n",
    "prediction = decorated_model.predict(model_input)\n",
    "\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed584261",
   "metadata": {},
   "source": [
    "The \"Prediction requested.\" log message now has two extra fields, the \"collections_in_last_12_months\" field and the \"debt_to_income_ratio\" field which were directly copied from the model input. The \"Prediction created.\" log message also has the \"credit_risk\" field, which is the prediction returned by the model.\n",
    "\n",
    "We now have a working logging decorator that can help us to do logging if the model does not do logging for itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e91c47",
   "metadata": {},
   "source": [
    "## Adding the Decorator to a Deployed Model\n",
    "\n",
    "Now that we have a decorator that works locally, we can deploy it with a model inside of a service. The [rest_model_service package](https://pypi.org/project/rest-model-service/) is able to host ML models and create a RESTful API for each individual model. We don't need to write any code to do this because the service can decorate the models that it hosts with decorators that we provide. You can learn more about the package in [this blog post](https://www.tekhnoal.com/rest-model-service.html). You can learn how the rest_model_service package can be configured to add decorators to a model in [this blog post](https://www.tekhnoal.com/ml-model-decorators.html).\n",
    "\n",
    "To install the service package, execute this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910ebd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install rest_model_service>=0.3.0\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da8c690",
   "metadata": {},
   "source": [
    "The configuration for our model and decorator looks like this:\n",
    "\n",
    "```yaml\n",
    "service_title: Credit Risk Model Service\n",
    "models:\n",
    "  - class_path: credit_risk_model.prediction.model.CreditRiskModel\n",
    "    create_endpoint: true\n",
    "    decorators:\n",
    "      - class_path: ml_model_logging.logging_decorator.LoggingDecorator\n",
    "        configuration:\n",
    "          input_fields: [\"collections_in_last_12_months\", \"debt_to_income_ratio\"]\n",
    "          output_fields: [\"credit_risk\"]\n",
    "logging:\n",
    "    version: 1\n",
    "    disable_existing_loggers: false\n",
    "    formatters:\n",
    "      json_formatter:\n",
    "        class: pythonjsonlogger.jsonlogger.JsonFormatter\n",
    "        format: \"%(asctime)s %(node_ip)s %(name)s %(levelname)s %(message)s\"\n",
    "    filters:\n",
    "      environment_info_filter:\n",
    "        \"()\": ml_model_logging.filters.EnvironmentInfoFilter\n",
    "        env_variables:\n",
    "        - NODE_IP\n",
    "    handlers:\n",
    "      stdout:\n",
    "        level: INFO\n",
    "        class: logging.StreamHandler\n",
    "        stream: ext://sys.stdout\n",
    "        formatter: json_formatter\n",
    "        filters:\n",
    "        - environment_info_filter\n",
    "    loggers:\n",
    "      root:\n",
    "        level: INFO\n",
    "        handlers:\n",
    "        - stdout\n",
    "        propagate: true\n",
    "```\n",
    "\n",
    "The two main sections in the file are the \"models\" section and the \"logging\" section. The models section is simpler and lists the CreditRiskModel, along with the LoggingDecorator. The decorators configuration simply adds an instance of the LoggingDecorator to the CreditRiskModel when the service starts up.\n",
    "\n",
    "The logging configuration is set up exactly like we set it up in the examples above except that it is in YAML format. The YAML is converted to a dictionary and passed directly into the logging.config.dictConfig() function.\n",
    "\n",
    "To run the service locally, execute these commands:\n",
    "\n",
    "```bash\n",
    "export NODE_IP=123.123.123.123\n",
    "export PYTHONPATH=./\n",
    "export REST_CONFIG=./configuration/rest_configuration.yaml\n",
    "uvicorn rest_model_service.main:app --reload\n",
    "```\n",
    "\n",
    "The NODE_IP environment variable is set so that the value can be added to the log messages through the filter we built above. The service should come up and can be accessed in a web browser at http://127.0.0.1:8000. When you access that URL you will be redirected to the documentation page that is generated by the FastAPI package:\n",
    "\n",
    "![Service Documentation](service_documentation_lfmlm.png)\n",
    "![Service Documentation]({attach}service_documentation_lfmlm.png){ width=100% }\n",
    "\n",
    "The documentation allows you to make requests against the API in order to try it out. Here's a prediction request against the insurance charges model:\n",
    "\n",
    "![Prediction Request](prediction_request_lfmlm.png)\n",
    "![Prediction Request]({attach}prediction_request_lfmlm.png){ width=100% }\n",
    "\n",
    "And the prediction result:\n",
    "\n",
    "![Prediction Response](prediction_response_lfmlm.png)\n",
    "![Prediction Response]({attach}prediction_response_lfmlm.png){ width=100% }\n",
    "\n",
    "\n",
    "The prediction made by the model had to go through the logging decorator that we configured into the service, so we got these two log records from the process:\n",
    "\n",
    "![Prediction Log](prediction_log_lfmlm.png)\n",
    "![Prediction Log]({attach}prediction_log_lfmlm.png){ width=100% }\n",
    "\n",
    "The local web service process emits the logs to stdout just as we configured it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461ad9b7",
   "metadata": {},
   "source": [
    "## Deploying the Model Service\n",
    "\n",
    "Now that we have a working service that is running locally, we can work on deploying it to Kubernetes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e41a6b5",
   "metadata": {},
   "source": [
    "### Creating a Docker Image\n",
    "\n",
    "Kubernetes needs to have a Docker image in order to deploy something, we'll build an image using this Dockerfile:\n",
    "\n",
    "```dockerfile\n",
    "# syntax=docker/dockerfile:1\n",
    "FROM python:3.9-slim as base\n",
    "\n",
    "WORKDIR /dependencies\n",
    "\n",
    "# installing git because we need to install the model package from the github repository\n",
    "RUN apt-get update -y && \\\n",
    "    apt-get install -y --no-install-recommends git\n",
    "\n",
    "# creating and activating a virtual environment\n",
    "ENV VIRTUAL_ENV=/opt/venv\n",
    "RUN python3 -m venv $VIRTUAL_ENV\n",
    "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
    "\n",
    "# installing dependencies\n",
    "COPY ./service_requirements.txt ./service_requirements.txt\n",
    "RUN pip install --no-cache -r service_requirements.txt\n",
    "\n",
    "FROM base as runtime\n",
    "\n",
    "ARG DATE_CREATED\n",
    "ARG REVISION\n",
    "ARG VERSION\n",
    "\n",
    "LABEL org.opencontainers.image.title=\"Logging for ML Models\"\n",
    "LABEL org.opencontainers.image.description=\"Logging for machine learning models.\"\n",
    "LABEL org.opencontainers.image.created=$DATE_CREATED\n",
    "LABEL org.opencontainers.image.authors=\"6666331+schmidtbri@users.noreply.github.com\"\n",
    "LABEL org.opencontainers.image.source=\"https://github.com/schmidtbri/logging-for-ml-models\"\n",
    "LABEL org.opencontainers.image.version=$VERSION\n",
    "LABEL org.opencontainers.image.revision=$REVISION\n",
    "LABEL org.opencontainers.image.licenses=\"MIT License\"\n",
    "LABEL org.opencontainers.image.base.name=\"python:3.9-slim\"\n",
    "\n",
    "WORKDIR /service\n",
    "\n",
    "# install packages\n",
    "RUN apt-get update -y && \\\n",
    "    apt-get install -y --no-install-recommends libgomp1 && \\\n",
    "    apt-get clean && \\\n",
    "    rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "COPY --from=base /opt/venv ./venv\n",
    "\n",
    "COPY ./ml_model_logging ./ml_model_logging\n",
    "COPY ./LICENSE ./LICENSE\n",
    "\n",
    "ENV PATH /service/venv/bin:$PATH\n",
    "ENV PYTHONPATH=\"${PYTHONPATH}:/service\"\n",
    "\n",
    "CMD [\"uvicorn\", \"rest_model_service.main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n",
    "```\n",
    "\n",
    "The Dockerfile includes a set of labels from the [Open Containers annotations specification](https://github.com/opencontainers/image-spec/blob/main/annotations.md). Most of the labels are hardcoded in the Dockerfile, but there are three that we need to add from the outside: the date created, the version, and the revision. To do this we'll pull some information into environment variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fde329ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T19:27:02.258700Z",
     "start_time": "2023-11-18T19:27:01.999119Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2023-11-18 16:18:50']\n",
      "['efc85b024aab5f3655e725037515a0a89d502208']\n"
     ]
    }
   ],
   "source": [
    "DATE_CREATED=!date +\"%Y-%m-%d %T\"\n",
    "REVISION=!git rev-parse HEAD\n",
    "\n",
    "!echo \"$DATE_CREATED\"\n",
    "!echo \"$REVISION\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef141e0",
   "metadata": {},
   "source": [
    "Now we can use the values to build the image. We'll also provide the version as a build argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5644a70c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T19:28:21.843496Z",
     "start_time": "2023-11-18T19:27:05.233792Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1A\u001B[1B\u001B[0G\u001B[?25l[+] Building 0.0s (0/2)                                    docker:desktop-linux\n",
      "\u001B[?25h\u001B[1A\u001B[0G\u001B[?25l[+] Building 0.2s (2/3)                                    docker:desktop-linux\n",
      "\u001B[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001B[0m\u001B[34m => => transferring dockerfile: 2.07kB                                     0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 382B                                          0.0s\n",
      "\u001B[0m => resolve image config for docker.io/docker/dockerfile:1                 0.1s\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 0.3s (2/3)                                    docker:desktop-linux\n",
      "\u001B[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001B[0m\u001B[34m => => transferring dockerfile: 2.07kB                                     0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 382B                                          0.0s\n",
      "\u001B[0m => resolve image config for docker.io/docker/dockerfile:1                 0.3s\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 0.5s (2/3)                                    docker:desktop-linux\n",
      "\u001B[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001B[0m\u001B[34m => => transferring dockerfile: 2.07kB                                     0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 382B                                          0.0s\n",
      "\u001B[0m => resolve image config for docker.io/docker/dockerfile:1                 0.4s\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 0.6s (2/3)                                    docker:desktop-linux\n",
      "\u001B[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001B[0m\u001B[34m => => transferring dockerfile: 2.07kB                                     0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 382B                                          0.0s\n",
      "\u001B[0m => resolve image config for docker.io/docker/dockerfile:1                 0.6s\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 0.8s (4/5)                                    docker:desktop-linux\n",
      "\u001B[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001B[0m\u001B[34m => => transferring dockerfile: 2.07kB                                     0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 382B                                          0.0s\n",
      "\u001B[0m\u001B[34m => resolve image config for docker.io/docker/dockerfile:1                 0.7s\n",
      "\u001B[0m\u001B[34m => CACHED docker-image://docker.io/docker/dockerfile:1@sha256:ac85f380a6  0.0s\n",
      "\u001B[0m => [internal] load metadata for docker.io/library/python:3.11-slim        0.0s\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 0.9s (4/5)                                    docker:desktop-linux\n",
      "\u001B[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001B[0m\u001B[34m => => transferring dockerfile: 2.07kB                                     0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 382B                                          0.0s\n",
      "\u001B[0m\u001B[34m => resolve image config for docker.io/docker/dockerfile:1                 0.7s\n",
      "\u001B[0m\u001B[34m => CACHED docker-image://docker.io/docker/dockerfile:1@sha256:ac85f380a6  0.0s\n",
      "\u001B[0m => [internal] load metadata for docker.io/library/python:3.11-slim        0.2s\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 1.1s (4/5)                                    docker:desktop-linux\n",
      "\u001B[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001B[0m\u001B[34m => => transferring dockerfile: 2.07kB                                     0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 382B                                          0.0s\n",
      "\u001B[0m\u001B[34m => resolve image config for docker.io/docker/dockerfile:1                 0.7s\n",
      "\u001B[0m\u001B[34m => CACHED docker-image://docker.io/docker/dockerfile:1@sha256:ac85f380a6  0.0s\n",
      "\u001B[0m => [internal] load metadata for docker.io/library/python:3.11-slim        0.3s\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 1.2s (5/5)                                    docker:desktop-linux\n",
      "\u001B[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001B[0m\u001B[34m => => transferring dockerfile: 2.07kB                                     0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 382B                                          0.0s\n",
      "\u001B[0m\u001B[34m => resolve image config for docker.io/docker/dockerfile:1                 0.7s\n",
      "\u001B[0m\u001B[34m => CACHED docker-image://docker.io/docker/dockerfile:1@sha256:ac85f380a6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load metadata for docker.io/library/python:3.11-slim        0.4s\n",
      "\u001B[0m\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 1.3s (14/18)                                  docker:desktop-linux\n",
      "\u001B[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001B[0m\u001B[34m => => transferring dockerfile: 2.07kB                                     0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 382B                                          0.0s\n",
      "\u001B[0m\u001B[34m => resolve image config for docker.io/docker/dockerfile:1                 0.7s\n",
      "\u001B[0m\u001B[34m => CACHED docker-image://docker.io/docker/dockerfile:1@sha256:ac85f380a6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load metadata for docker.io/library/python:3.11-slim        0.4s\n",
      "\u001B[0m\u001B[34m => [base 1/7] FROM docker.io/library/python:3.11-slim@sha256:f89d4d260b6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load build context                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 1.14kB                                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 2/7] WORKDIR /dependencies                                0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 3/7] RUN apt-get update -y &&     apt-get install -y --n  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 4/7] RUN if [ \"$(uname)\" = \"Linux\" ]; then     apt-get u  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 5/7] RUN python3 -m venv /opt/venv                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 6/7] COPY ./service_requirements.txt ./service_requireme  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 7/7] RUN pip install --no-cache -r service_requirements.  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [runtime 1/5] WORKDIR /service                                  0.0s\n",
      "\u001B[0m => [runtime 2/5] RUN apt-get update -y &&     apt-get install -y --no-in  0.1s\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 1.5s (14/18)                                  docker:desktop-linux\n",
      "\u001B[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001B[0m\u001B[34m => => transferring dockerfile: 2.07kB                                     0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 382B                                          0.0s\n",
      "\u001B[0m\u001B[34m => resolve image config for docker.io/docker/dockerfile:1                 0.7s\n",
      "\u001B[0m\u001B[34m => CACHED docker-image://docker.io/docker/dockerfile:1@sha256:ac85f380a6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load metadata for docker.io/library/python:3.11-slim        0.4s\n",
      "\u001B[0m\u001B[34m => [base 1/7] FROM docker.io/library/python:3.11-slim@sha256:f89d4d260b6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load build context                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 1.14kB                                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 2/7] WORKDIR /dependencies                                0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 3/7] RUN apt-get update -y &&     apt-get install -y --n  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 4/7] RUN if [ \"$(uname)\" = \"Linux\" ]; then     apt-get u  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 5/7] RUN python3 -m venv /opt/venv                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 6/7] COPY ./service_requirements.txt ./service_requireme  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 7/7] RUN pip install --no-cache -r service_requirements.  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [runtime 1/5] WORKDIR /service                                  0.0s\n",
      "\u001B[0m => [runtime 2/5] RUN apt-get update -y &&     apt-get install -y --no-in  0.2s\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 1.6s (14/18)                                  docker:desktop-linux\n",
      "\u001B[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001B[0m\u001B[34m => => transferring dockerfile: 2.07kB                                     0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 382B                                          0.0s\n",
      "\u001B[0m\u001B[34m => resolve image config for docker.io/docker/dockerfile:1                 0.7s\n",
      "\u001B[0m\u001B[34m => CACHED docker-image://docker.io/docker/dockerfile:1@sha256:ac85f380a6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load metadata for docker.io/library/python:3.11-slim        0.4s\n",
      "\u001B[0m\u001B[34m => [base 1/7] FROM docker.io/library/python:3.11-slim@sha256:f89d4d260b6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load build context                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 1.14kB                                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 2/7] WORKDIR /dependencies                                0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 3/7] RUN apt-get update -y &&     apt-get install -y --n  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 4/7] RUN if [ \"$(uname)\" = \"Linux\" ]; then     apt-get u  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 5/7] RUN python3 -m venv /opt/venv                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 6/7] COPY ./service_requirements.txt ./service_requireme  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 7/7] RUN pip install --no-cache -r service_requirements.  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [runtime 1/5] WORKDIR /service                                  0.0s\n",
      "\u001B[0m => [runtime 2/5] RUN apt-get update -y &&     apt-get install -y --no-in  0.4s\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 1.8s (14/18)                                  docker:desktop-linux\n",
      "\u001B[34m => => transferring dockerfile: 2.07kB                                     0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 382B                                          0.0s\n",
      "\u001B[0m\u001B[34m => resolve image config for docker.io/docker/dockerfile:1                 0.7s\n",
      "\u001B[0m\u001B[34m => CACHED docker-image://docker.io/docker/dockerfile:1@sha256:ac85f380a6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load metadata for docker.io/library/python:3.11-slim        0.4s\n",
      "\u001B[0m\u001B[34m => [base 1/7] FROM docker.io/library/python:3.11-slim@sha256:f89d4d260b6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load build context                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 1.14kB                                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 2/7] WORKDIR /dependencies                                0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 3/7] RUN apt-get update -y &&     apt-get install -y --n  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 4/7] RUN if [ \"$(uname)\" = \"Linux\" ]; then     apt-get u  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 5/7] RUN python3 -m venv /opt/venv                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 6/7] COPY ./service_requirements.txt ./service_requireme  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 7/7] RUN pip install --no-cache -r service_requirements.  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [runtime 1/5] WORKDIR /service                                  0.0s\n",
      "\u001B[0m => [runtime 2/5] RUN apt-get update -y &&     apt-get install -y --no-in  0.5s\n",
      "\u001B[2m => => # Get:1 http://deb.debian.org/debian bookworm InRelease [151 kB]        \n",
      "\u001B[0m\u001B[2m => => # Get:2 http://deb.debian.org/debian bookworm-updates InRelease [52.1 kB\n",
      "\u001B[0m\u001B[2m => => # ]                                                                     \n",
      "\u001B[0m\u001B[2m => => # Get:3 http://deb.debian.org/debian-security bookworm-security InReleas\n",
      "\u001B[0m\u001B[2m => => # e [48.0 kB]                                                           \n",
      "\u001B[0m\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 1.9s (14/18)                                  docker:desktop-linux\n",
      "\u001B[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 382B                                          0.0s\n",
      "\u001B[0m\u001B[34m => resolve image config for docker.io/docker/dockerfile:1                 0.7s\n",
      "\u001B[0m\u001B[34m => CACHED docker-image://docker.io/docker/dockerfile:1@sha256:ac85f380a6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load metadata for docker.io/library/python:3.11-slim        0.4s\n",
      "\u001B[0m\u001B[34m => [base 1/7] FROM docker.io/library/python:3.11-slim@sha256:f89d4d260b6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load build context                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 1.14kB                                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 2/7] WORKDIR /dependencies                                0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 3/7] RUN apt-get update -y &&     apt-get install -y --n  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 4/7] RUN if [ \"$(uname)\" = \"Linux\" ]; then     apt-get u  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 5/7] RUN python3 -m venv /opt/venv                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 6/7] COPY ./service_requirements.txt ./service_requireme  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 7/7] RUN pip install --no-cache -r service_requirements.  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [runtime 1/5] WORKDIR /service                                  0.0s\n",
      "\u001B[0m => [runtime 2/5] RUN apt-get update -y &&     apt-get install -y --no-in  0.7s\n",
      "\u001B[2m => => # Get:2 http://deb.debian.org/debian bookworm-updates InRelease [52.1 kB\n",
      "\u001B[0m\u001B[2m => => # ]                                                                     \n",
      "\u001B[0m\u001B[2m => => # Get:3 http://deb.debian.org/debian-security bookworm-security InReleas\n",
      "\u001B[0m\u001B[2m => => # e [48.0 kB]                                                           \n",
      "\u001B[0m\u001B[2m => => # Get:4 http://deb.debian.org/debian bookworm/main arm64 Packages [8681 \n",
      "\u001B[0m\u001B[2m => => # kB]                                                                   \n",
      "\u001B[0m\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 2.1s (14/18)                                  docker:desktop-linux\n",
      "\u001B[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 382B                                          0.0s\n",
      "\u001B[0m\u001B[34m => resolve image config for docker.io/docker/dockerfile:1                 0.7s\n",
      "\u001B[0m\u001B[34m => CACHED docker-image://docker.io/docker/dockerfile:1@sha256:ac85f380a6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load metadata for docker.io/library/python:3.11-slim        0.4s\n",
      "\u001B[0m\u001B[34m => [base 1/7] FROM docker.io/library/python:3.11-slim@sha256:f89d4d260b6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load build context                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 1.14kB                                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 2/7] WORKDIR /dependencies                                0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 3/7] RUN apt-get update -y &&     apt-get install -y --n  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 4/7] RUN if [ \"$(uname)\" = \"Linux\" ]; then     apt-get u  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 5/7] RUN python3 -m venv /opt/venv                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 6/7] COPY ./service_requirements.txt ./service_requireme  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 7/7] RUN pip install --no-cache -r service_requirements.  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [runtime 1/5] WORKDIR /service                                  0.0s\n",
      "\u001B[0m => [runtime 2/5] RUN apt-get update -y &&     apt-get install -y --no-in  0.8s\n",
      "\u001B[2m => => # Get:2 http://deb.debian.org/debian bookworm-updates InRelease [52.1 kB\n",
      "\u001B[0m\u001B[2m => => # ]                                                                     \n",
      "\u001B[0m\u001B[2m => => # Get:3 http://deb.debian.org/debian-security bookworm-security InReleas\n",
      "\u001B[0m\u001B[2m => => # e [48.0 kB]                                                           \n",
      "\u001B[0m\u001B[2m => => # Get:4 http://deb.debian.org/debian bookworm/main arm64 Packages [8681 \n",
      "\u001B[0m\u001B[2m => => # kB]                                                                   \n",
      "\u001B[0m\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 2.2s (14/18)                                  docker:desktop-linux\n",
      "\u001B[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 382B                                          0.0s\n",
      "\u001B[0m\u001B[34m => resolve image config for docker.io/docker/dockerfile:1                 0.7s\n",
      "\u001B[0m\u001B[34m => CACHED docker-image://docker.io/docker/dockerfile:1@sha256:ac85f380a6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load metadata for docker.io/library/python:3.11-slim        0.4s\n",
      "\u001B[0m\u001B[34m => [base 1/7] FROM docker.io/library/python:3.11-slim@sha256:f89d4d260b6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load build context                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 1.14kB                                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 2/7] WORKDIR /dependencies                                0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 3/7] RUN apt-get update -y &&     apt-get install -y --n  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 4/7] RUN if [ \"$(uname)\" = \"Linux\" ]; then     apt-get u  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 5/7] RUN python3 -m venv /opt/venv                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 6/7] COPY ./service_requirements.txt ./service_requireme  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 7/7] RUN pip install --no-cache -r service_requirements.  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [runtime 1/5] WORKDIR /service                                  0.0s\n",
      "\u001B[0m => [runtime 2/5] RUN apt-get update -y &&     apt-get install -y --no-in  1.0s\n",
      "\u001B[2m => => # Get:2 http://deb.debian.org/debian bookworm-updates InRelease [52.1 kB\n",
      "\u001B[0m\u001B[2m => => # ]                                                                     \n",
      "\u001B[0m\u001B[2m => => # Get:3 http://deb.debian.org/debian-security bookworm-security InReleas\n",
      "\u001B[0m\u001B[2m => => # e [48.0 kB]                                                           \n",
      "\u001B[0m\u001B[2m => => # Get:4 http://deb.debian.org/debian bookworm/main arm64 Packages [8681 \n",
      "\u001B[0m\u001B[2m => => # kB]                                                                   \n",
      "\u001B[0m\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 2.4s (14/18)                                  docker:desktop-linux\n",
      "\u001B[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 382B                                          0.0s\n",
      "\u001B[0m\u001B[34m => resolve image config for docker.io/docker/dockerfile:1                 0.7s\n",
      "\u001B[0m\u001B[34m => CACHED docker-image://docker.io/docker/dockerfile:1@sha256:ac85f380a6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load metadata for docker.io/library/python:3.11-slim        0.4s\n",
      "\u001B[0m\u001B[34m => [base 1/7] FROM docker.io/library/python:3.11-slim@sha256:f89d4d260b6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load build context                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 1.14kB                                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 2/7] WORKDIR /dependencies                                0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 3/7] RUN apt-get update -y &&     apt-get install -y --n  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 4/7] RUN if [ \"$(uname)\" = \"Linux\" ]; then     apt-get u  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 5/7] RUN python3 -m venv /opt/venv                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 6/7] COPY ./service_requirements.txt ./service_requireme  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 7/7] RUN pip install --no-cache -r service_requirements.  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [runtime 1/5] WORKDIR /service                                  0.0s\n",
      "\u001B[0m => [runtime 2/5] RUN apt-get update -y &&     apt-get install -y --no-in  1.1s\n",
      "\u001B[2m => => # Get:2 http://deb.debian.org/debian bookworm-updates InRelease [52.1 kB\n",
      "\u001B[0m\u001B[2m => => # ]                                                                     \n",
      "\u001B[0m\u001B[2m => => # Get:3 http://deb.debian.org/debian-security bookworm-security InReleas\n",
      "\u001B[0m\u001B[2m => => # e [48.0 kB]                                                           \n",
      "\u001B[0m\u001B[2m => => # Get:4 http://deb.debian.org/debian bookworm/main arm64 Packages [8681 \n",
      "\u001B[0m\u001B[2m => => # kB]                                                                   \n",
      "\u001B[0m\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 2.5s (14/18)                                  docker:desktop-linux\n",
      "\u001B[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 382B                                          0.0s\n",
      "\u001B[0m\u001B[34m => resolve image config for docker.io/docker/dockerfile:1                 0.7s\n",
      "\u001B[0m\u001B[34m => CACHED docker-image://docker.io/docker/dockerfile:1@sha256:ac85f380a6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load metadata for docker.io/library/python:3.11-slim        0.4s\n",
      "\u001B[0m\u001B[34m => [base 1/7] FROM docker.io/library/python:3.11-slim@sha256:f89d4d260b6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load build context                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 1.14kB                                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 2/7] WORKDIR /dependencies                                0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 3/7] RUN apt-get update -y &&     apt-get install -y --n  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 4/7] RUN if [ \"$(uname)\" = \"Linux\" ]; then     apt-get u  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 5/7] RUN python3 -m venv /opt/venv                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 6/7] COPY ./service_requirements.txt ./service_requireme  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 7/7] RUN pip install --no-cache -r service_requirements.  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [runtime 1/5] WORKDIR /service                                  0.0s\n",
      "\u001B[0m => [runtime 2/5] RUN apt-get update -y &&     apt-get install -y --no-in  1.3s\n",
      "\u001B[2m => => # Get:2 http://deb.debian.org/debian bookworm-updates InRelease [52.1 kB\n",
      "\u001B[0m\u001B[2m => => # ]                                                                     \n",
      "\u001B[0m\u001B[2m => => # Get:3 http://deb.debian.org/debian-security bookworm-security InReleas\n",
      "\u001B[0m\u001B[2m => => # e [48.0 kB]                                                           \n",
      "\u001B[0m\u001B[2m => => # Get:4 http://deb.debian.org/debian bookworm/main arm64 Packages [8681 \n",
      "\u001B[0m\u001B[2m => => # kB]                                                                   \n",
      "\u001B[0m\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 2.7s (14/18)                                  docker:desktop-linux\n",
      "\u001B[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 382B                                          0.0s\n",
      "\u001B[0m\u001B[34m => resolve image config for docker.io/docker/dockerfile:1                 0.7s\n",
      "\u001B[0m\u001B[34m => CACHED docker-image://docker.io/docker/dockerfile:1@sha256:ac85f380a6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load metadata for docker.io/library/python:3.11-slim        0.4s\n",
      "\u001B[0m\u001B[34m => [base 1/7] FROM docker.io/library/python:3.11-slim@sha256:f89d4d260b6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load build context                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 1.14kB                                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 2/7] WORKDIR /dependencies                                0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 3/7] RUN apt-get update -y &&     apt-get install -y --n  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 4/7] RUN if [ \"$(uname)\" = \"Linux\" ]; then     apt-get u  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 5/7] RUN python3 -m venv /opt/venv                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 6/7] COPY ./service_requirements.txt ./service_requireme  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 7/7] RUN pip install --no-cache -r service_requirements.  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [runtime 1/5] WORKDIR /service                                  0.0s\n",
      "\u001B[0m => [runtime 2/5] RUN apt-get update -y &&     apt-get install -y --no-in  1.4s\n",
      "\u001B[2m => => # Get:2 http://deb.debian.org/debian bookworm-updates InRelease [52.1 kB\n",
      "\u001B[0m\u001B[2m => => # ]                                                                     \n",
      "\u001B[0m\u001B[2m => => # Get:3 http://deb.debian.org/debian-security bookworm-security InReleas\n",
      "\u001B[0m\u001B[2m => => # e [48.0 kB]                                                           \n",
      "\u001B[0m\u001B[2m => => # Get:4 http://deb.debian.org/debian bookworm/main arm64 Packages [8681 \n",
      "\u001B[0m\u001B[2m => => # kB]                                                                   \n",
      "\u001B[0m\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 2.8s (14/18)                                  docker:desktop-linux\n",
      "\u001B[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 382B                                          0.0s\n",
      "\u001B[0m\u001B[34m => resolve image config for docker.io/docker/dockerfile:1                 0.7s\n",
      "\u001B[0m\u001B[34m => CACHED docker-image://docker.io/docker/dockerfile:1@sha256:ac85f380a6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load metadata for docker.io/library/python:3.11-slim        0.4s\n",
      "\u001B[0m\u001B[34m => [base 1/7] FROM docker.io/library/python:3.11-slim@sha256:f89d4d260b6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load build context                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 1.14kB                                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 2/7] WORKDIR /dependencies                                0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 3/7] RUN apt-get update -y &&     apt-get install -y --n  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 4/7] RUN if [ \"$(uname)\" = \"Linux\" ]; then     apt-get u  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 5/7] RUN python3 -m venv /opt/venv                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 6/7] COPY ./service_requirements.txt ./service_requireme  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 7/7] RUN pip install --no-cache -r service_requirements.  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [runtime 1/5] WORKDIR /service                                  0.0s\n",
      "\u001B[0m => [runtime 2/5] RUN apt-get update -y &&     apt-get install -y --no-in  1.6s\n",
      "\u001B[2m => => # Get:2 http://deb.debian.org/debian bookworm-updates InRelease [52.1 kB\n",
      "\u001B[0m\u001B[2m => => # ]                                                                     \n",
      "\u001B[0m\u001B[2m => => # Get:3 http://deb.debian.org/debian-security bookworm-security InReleas\n",
      "\u001B[0m\u001B[2m => => # e [48.0 kB]                                                           \n",
      "\u001B[0m\u001B[2m => => # Get:4 http://deb.debian.org/debian bookworm/main arm64 Packages [8681 \n",
      "\u001B[0m\u001B[2m => => # kB]                                                                   \n",
      "\u001B[0m\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 3.0s (14/18)                                  docker:desktop-linux\n",
      "\u001B[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 382B                                          0.0s\n",
      "\u001B[0m\u001B[34m => resolve image config for docker.io/docker/dockerfile:1                 0.7s\n",
      "\u001B[0m\u001B[34m => CACHED docker-image://docker.io/docker/dockerfile:1@sha256:ac85f380a6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load metadata for docker.io/library/python:3.11-slim        0.4s\n",
      "\u001B[0m\u001B[34m => [base 1/7] FROM docker.io/library/python:3.11-slim@sha256:f89d4d260b6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load build context                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 1.14kB                                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 2/7] WORKDIR /dependencies                                0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 3/7] RUN apt-get update -y &&     apt-get install -y --n  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 4/7] RUN if [ \"$(uname)\" = \"Linux\" ]; then     apt-get u  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 5/7] RUN python3 -m venv /opt/venv                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 6/7] COPY ./service_requirements.txt ./service_requireme  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 7/7] RUN pip install --no-cache -r service_requirements.  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [runtime 1/5] WORKDIR /service                                  0.0s\n",
      "\u001B[0m => [runtime 2/5] RUN apt-get update -y &&     apt-get install -y --no-in  1.7s\n",
      "\u001B[2m => => # Get:2 http://deb.debian.org/debian bookworm-updates InRelease [52.1 kB\n",
      "\u001B[0m\u001B[2m => => # ]                                                                     \n",
      "\u001B[0m\u001B[2m => => # Get:3 http://deb.debian.org/debian-security bookworm-security InReleas\n",
      "\u001B[0m\u001B[2m => => # e [48.0 kB]                                                           \n",
      "\u001B[0m\u001B[2m => => # Get:4 http://deb.debian.org/debian bookworm/main arm64 Packages [8681 \n",
      "\u001B[0m\u001B[2m => => # kB]                                                                   \n",
      "\u001B[0m\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 3.1s (14/18)                                  docker:desktop-linux\n",
      "\u001B[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 382B                                          0.0s\n",
      "\u001B[0m\u001B[34m => resolve image config for docker.io/docker/dockerfile:1                 0.7s\n",
      "\u001B[0m\u001B[34m => CACHED docker-image://docker.io/docker/dockerfile:1@sha256:ac85f380a6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load metadata for docker.io/library/python:3.11-slim        0.4s\n",
      "\u001B[0m\u001B[34m => [base 1/7] FROM docker.io/library/python:3.11-slim@sha256:f89d4d260b6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load build context                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 1.14kB                                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 2/7] WORKDIR /dependencies                                0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 3/7] RUN apt-get update -y &&     apt-get install -y --n  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 4/7] RUN if [ \"$(uname)\" = \"Linux\" ]; then     apt-get u  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 5/7] RUN python3 -m venv /opt/venv                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 6/7] COPY ./service_requirements.txt ./service_requireme  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 7/7] RUN pip install --no-cache -r service_requirements.  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [runtime 1/5] WORKDIR /service                                  0.0s\n",
      "\u001B[0m => [runtime 2/5] RUN apt-get update -y &&     apt-get install -y --no-in  1.9s\n",
      "\u001B[2m => => # Get:2 http://deb.debian.org/debian bookworm-updates InRelease [52.1 kB\n",
      "\u001B[0m\u001B[2m => => # ]                                                                     \n",
      "\u001B[0m\u001B[2m => => # Get:3 http://deb.debian.org/debian-security bookworm-security InReleas\n",
      "\u001B[0m\u001B[2m => => # e [48.0 kB]                                                           \n",
      "\u001B[0m\u001B[2m => => # Get:4 http://deb.debian.org/debian bookworm/main arm64 Packages [8681 \n",
      "\u001B[0m\u001B[2m => => # kB]                                                                   \n",
      "\u001B[0m\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 3.3s (14/18)                                  docker:desktop-linux\n",
      "\u001B[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 382B                                          0.0s\n",
      "\u001B[0m\u001B[34m => resolve image config for docker.io/docker/dockerfile:1                 0.7s\n",
      "\u001B[0m\u001B[34m => CACHED docker-image://docker.io/docker/dockerfile:1@sha256:ac85f380a6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load metadata for docker.io/library/python:3.11-slim        0.4s\n",
      "\u001B[0m\u001B[34m => [base 1/7] FROM docker.io/library/python:3.11-slim@sha256:f89d4d260b6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load build context                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 1.14kB                                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 2/7] WORKDIR /dependencies                                0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 3/7] RUN apt-get update -y &&     apt-get install -y --n  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 4/7] RUN if [ \"$(uname)\" = \"Linux\" ]; then     apt-get u  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 5/7] RUN python3 -m venv /opt/venv                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 6/7] COPY ./service_requirements.txt ./service_requireme  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 7/7] RUN pip install --no-cache -r service_requirements.  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [runtime 1/5] WORKDIR /service                                  0.0s\n",
      "\u001B[0m => [runtime 2/5] RUN apt-get update -y &&     apt-get install -y --no-in  2.0s\n",
      "\u001B[2m => => # Get:2 http://deb.debian.org/debian bookworm-updates InRelease [52.1 kB\n",
      "\u001B[0m\u001B[2m => => # ]                                                                     \n",
      "\u001B[0m\u001B[2m => => # Get:3 http://deb.debian.org/debian-security bookworm-security InReleas\n",
      "\u001B[0m\u001B[2m => => # e [48.0 kB]                                                           \n",
      "\u001B[0m\u001B[2m => => # Get:4 http://deb.debian.org/debian bookworm/main arm64 Packages [8681 \n",
      "\u001B[0m\u001B[2m => => # kB]                                                                   \n",
      "\u001B[0m\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 3.4s (14/18)                                  docker:desktop-linux\n",
      "\u001B[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 382B                                          0.0s\n",
      "\u001B[0m\u001B[34m => resolve image config for docker.io/docker/dockerfile:1                 0.7s\n",
      "\u001B[0m\u001B[34m => CACHED docker-image://docker.io/docker/dockerfile:1@sha256:ac85f380a6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load metadata for docker.io/library/python:3.11-slim        0.4s\n",
      "\u001B[0m\u001B[34m => [base 1/7] FROM docker.io/library/python:3.11-slim@sha256:f89d4d260b6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load build context                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 1.14kB                                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 2/7] WORKDIR /dependencies                                0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 3/7] RUN apt-get update -y &&     apt-get install -y --n  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 4/7] RUN if [ \"$(uname)\" = \"Linux\" ]; then     apt-get u  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 5/7] RUN python3 -m venv /opt/venv                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 6/7] COPY ./service_requirements.txt ./service_requireme  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 7/7] RUN pip install --no-cache -r service_requirements.  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [runtime 1/5] WORKDIR /service                                  0.0s\n",
      "\u001B[0m => [runtime 2/5] RUN apt-get update -y &&     apt-get install -y --no-in  2.2s\n",
      "\u001B[2m => => # Get:2 http://deb.debian.org/debian bookworm-updates InRelease [52.1 kB\n",
      "\u001B[0m\u001B[2m => => # ]                                                                     \n",
      "\u001B[0m\u001B[2m => => # Get:3 http://deb.debian.org/debian-security bookworm-security InReleas\n",
      "\u001B[0m\u001B[2m => => # e [48.0 kB]                                                           \n",
      "\u001B[0m\u001B[2m => => # Get:4 http://deb.debian.org/debian bookworm/main arm64 Packages [8681 \n",
      "\u001B[0m\u001B[2m => => # kB]                                                                   \n",
      "\u001B[0m\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 3.6s (14/18)                                  docker:desktop-linux\n",
      "\u001B[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 382B                                          0.0s\n",
      "\u001B[0m\u001B[34m => resolve image config for docker.io/docker/dockerfile:1                 0.7s\n",
      "\u001B[0m\u001B[34m => CACHED docker-image://docker.io/docker/dockerfile:1@sha256:ac85f380a6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load metadata for docker.io/library/python:3.11-slim        0.4s\n",
      "\u001B[0m\u001B[34m => [base 1/7] FROM docker.io/library/python:3.11-slim@sha256:f89d4d260b6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load build context                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 1.14kB                                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 2/7] WORKDIR /dependencies                                0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 3/7] RUN apt-get update -y &&     apt-get install -y --n  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 4/7] RUN if [ \"$(uname)\" = \"Linux\" ]; then     apt-get u  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 5/7] RUN python3 -m venv /opt/venv                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 6/7] COPY ./service_requirements.txt ./service_requireme  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 7/7] RUN pip install --no-cache -r service_requirements.  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [runtime 1/5] WORKDIR /service                                  0.0s\n",
      "\u001B[0m => [runtime 2/5] RUN apt-get update -y &&     apt-get install -y --no-in  2.3s\n",
      "\u001B[2m => => # Get:2 http://deb.debian.org/debian bookworm-updates InRelease [52.1 kB\n",
      "\u001B[0m\u001B[2m => => # ]                                                                     \n",
      "\u001B[0m\u001B[2m => => # Get:3 http://deb.debian.org/debian-security bookworm-security InReleas\n",
      "\u001B[0m\u001B[2m => => # e [48.0 kB]                                                           \n",
      "\u001B[0m\u001B[2m => => # Get:4 http://deb.debian.org/debian bookworm/main arm64 Packages [8681 \n",
      "\u001B[0m\u001B[2m => => # kB]                                                                   \n",
      "\u001B[0m\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 3.7s (14/18)                                  docker:desktop-linux\n",
      "\u001B[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 382B                                          0.0s\n",
      "\u001B[0m\u001B[34m => resolve image config for docker.io/docker/dockerfile:1                 0.7s\n",
      "\u001B[0m\u001B[34m => CACHED docker-image://docker.io/docker/dockerfile:1@sha256:ac85f380a6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load metadata for docker.io/library/python:3.11-slim        0.4s\n",
      "\u001B[0m\u001B[34m => [base 1/7] FROM docker.io/library/python:3.11-slim@sha256:f89d4d260b6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load build context                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 1.14kB                                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 2/7] WORKDIR /dependencies                                0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 3/7] RUN apt-get update -y &&     apt-get install -y --n  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 4/7] RUN if [ \"$(uname)\" = \"Linux\" ]; then     apt-get u  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 5/7] RUN python3 -m venv /opt/venv                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 6/7] COPY ./service_requirements.txt ./service_requireme  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 7/7] RUN pip install --no-cache -r service_requirements.  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [runtime 1/5] WORKDIR /service                                  0.0s\n",
      "\u001B[0m => [runtime 2/5] RUN apt-get update -y &&     apt-get install -y --no-in  2.4s\n",
      "\u001B[2m => => # Get:3 http://deb.debian.org/debian-security bookworm-security InReleas\n",
      "\u001B[0m\u001B[2m => => # e [48.0 kB]                                                           \n",
      "\u001B[0m\u001B[2m => => # Get:4 http://deb.debian.org/debian bookworm/main arm64 Packages [8681 \n",
      "\u001B[0m\u001B[2m => => # kB]                                                                   \n",
      "\u001B[0m\u001B[2m => => # Get:5 http://deb.debian.org/debian bookworm-updates/main arm64 Package\n",
      "\u001B[0m\u001B[2m => => # s [6672 B]                                                            \n",
      "\u001B[0m\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 3.8s (14/18)                                  docker:desktop-linux\n",
      "\u001B[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 382B                                          0.0s\n",
      "\u001B[0m\u001B[34m => resolve image config for docker.io/docker/dockerfile:1                 0.7s\n",
      "\u001B[0m\u001B[34m => CACHED docker-image://docker.io/docker/dockerfile:1@sha256:ac85f380a6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load metadata for docker.io/library/python:3.11-slim        0.4s\n",
      "\u001B[0m\u001B[34m => [base 1/7] FROM docker.io/library/python:3.11-slim@sha256:f89d4d260b6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load build context                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 1.14kB                                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 2/7] WORKDIR /dependencies                                0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 3/7] RUN apt-get update -y &&     apt-get install -y --n  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 4/7] RUN if [ \"$(uname)\" = \"Linux\" ]; then     apt-get u  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 5/7] RUN python3 -m venv /opt/venv                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 6/7] COPY ./service_requirements.txt ./service_requireme  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 7/7] RUN pip install --no-cache -r service_requirements.  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [runtime 1/5] WORKDIR /service                                  0.0s\n",
      "\u001B[0m => [runtime 2/5] RUN apt-get update -y &&     apt-get install -y --no-in  2.6s\n",
      "\u001B[2m => => # Get:4 http://deb.debian.org/debian bookworm/main arm64 Packages [8681 \n",
      "\u001B[0m\u001B[2m => => # kB]                                                                   \n",
      "\u001B[0m\u001B[2m => => # Get:5 http://deb.debian.org/debian bookworm-updates/main arm64 Package\n",
      "\u001B[0m\u001B[2m => => # s [6672 B]                                                            \n",
      "\u001B[0m\u001B[2m => => # Get:6 http://deb.debian.org/debian-security bookworm-security/main arm\n",
      "\u001B[0m\u001B[2m => => # 64 Packages [98.6 kB]                                                 \n",
      "\u001B[0m\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 4.0s (14/18)                                  docker:desktop-linux\n",
      "\u001B[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 382B                                          0.0s\n",
      "\u001B[0m\u001B[34m => resolve image config for docker.io/docker/dockerfile:1                 0.7s\n",
      "\u001B[0m\u001B[34m => CACHED docker-image://docker.io/docker/dockerfile:1@sha256:ac85f380a6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load metadata for docker.io/library/python:3.11-slim        0.4s\n",
      "\u001B[0m\u001B[34m => [base 1/7] FROM docker.io/library/python:3.11-slim@sha256:f89d4d260b6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load build context                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 1.14kB                                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 2/7] WORKDIR /dependencies                                0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 3/7] RUN apt-get update -y &&     apt-get install -y --n  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 4/7] RUN if [ \"$(uname)\" = \"Linux\" ]; then     apt-get u  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 5/7] RUN python3 -m venv /opt/venv                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 6/7] COPY ./service_requirements.txt ./service_requireme  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 7/7] RUN pip install --no-cache -r service_requirements.  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [runtime 1/5] WORKDIR /service                                  0.0s\n",
      "\u001B[0m => [runtime 2/5] RUN apt-get update -y &&     apt-get install -y --no-in  2.7s\n",
      "\u001B[2m => => # Get:4 http://deb.debian.org/debian bookworm/main arm64 Packages [8681 \n",
      "\u001B[0m\u001B[2m => => # kB]                                                                   \n",
      "\u001B[0m\u001B[2m => => # Get:5 http://deb.debian.org/debian bookworm-updates/main arm64 Package\n",
      "\u001B[0m\u001B[2m => => # s [6672 B]                                                            \n",
      "\u001B[0m\u001B[2m => => # Get:6 http://deb.debian.org/debian-security bookworm-security/main arm\n",
      "\u001B[0m\u001B[2m => => # 64 Packages [98.6 kB]                                                 \n",
      "\u001B[0m\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 4.1s (14/18)                                  docker:desktop-linux\n",
      "\u001B[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 382B                                          0.0s\n",
      "\u001B[0m\u001B[34m => resolve image config for docker.io/docker/dockerfile:1                 0.7s\n",
      "\u001B[0m\u001B[34m => CACHED docker-image://docker.io/docker/dockerfile:1@sha256:ac85f380a6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load metadata for docker.io/library/python:3.11-slim        0.4s\n",
      "\u001B[0m\u001B[34m => [base 1/7] FROM docker.io/library/python:3.11-slim@sha256:f89d4d260b6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load build context                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 1.14kB                                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 2/7] WORKDIR /dependencies                                0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 3/7] RUN apt-get update -y &&     apt-get install -y --n  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 4/7] RUN if [ \"$(uname)\" = \"Linux\" ]; then     apt-get u  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 5/7] RUN python3 -m venv /opt/venv                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 6/7] COPY ./service_requirements.txt ./service_requireme  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 7/7] RUN pip install --no-cache -r service_requirements.  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [runtime 1/5] WORKDIR /service                                  0.0s\n",
      "\u001B[0m => [runtime 2/5] RUN apt-get update -y &&     apt-get install -y --no-in  2.9s\n",
      "\u001B[2m => => # Get:4 http://deb.debian.org/debian bookworm/main arm64 Packages [8681 \n",
      "\u001B[0m\u001B[2m => => # kB]                                                                   \n",
      "\u001B[0m\u001B[2m => => # Get:5 http://deb.debian.org/debian bookworm-updates/main arm64 Package\n",
      "\u001B[0m\u001B[2m => => # s [6672 B]                                                            \n",
      "\u001B[0m\u001B[2m => => # Get:6 http://deb.debian.org/debian-security bookworm-security/main arm\n",
      "\u001B[0m\u001B[2m => => # 64 Packages [98.6 kB]                                                 \n",
      "\u001B[0m\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 4.3s (14/18)                                  docker:desktop-linux\n",
      "\u001B[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 382B                                          0.0s\n",
      "\u001B[0m\u001B[34m => resolve image config for docker.io/docker/dockerfile:1                 0.7s\n",
      "\u001B[0m\u001B[34m => CACHED docker-image://docker.io/docker/dockerfile:1@sha256:ac85f380a6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load metadata for docker.io/library/python:3.11-slim        0.4s\n",
      "\u001B[0m\u001B[34m => [base 1/7] FROM docker.io/library/python:3.11-slim@sha256:f89d4d260b6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load build context                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 1.14kB                                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 2/7] WORKDIR /dependencies                                0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 3/7] RUN apt-get update -y &&     apt-get install -y --n  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 4/7] RUN if [ \"$(uname)\" = \"Linux\" ]; then     apt-get u  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 5/7] RUN python3 -m venv /opt/venv                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 6/7] COPY ./service_requirements.txt ./service_requireme  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 7/7] RUN pip install --no-cache -r service_requirements.  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [runtime 1/5] WORKDIR /service                                  0.0s\n",
      "\u001B[0m => [runtime 2/5] RUN apt-get update -y &&     apt-get install -y --no-in  3.0s\n",
      "\u001B[2m => => # Get:4 http://deb.debian.org/debian bookworm/main arm64 Packages [8681 \n",
      "\u001B[0m\u001B[2m => => # kB]                                                                   \n",
      "\u001B[0m\u001B[2m => => # Get:5 http://deb.debian.org/debian bookworm-updates/main arm64 Package\n",
      "\u001B[0m\u001B[2m => => # s [6672 B]                                                            \n",
      "\u001B[0m\u001B[2m => => # Get:6 http://deb.debian.org/debian-security bookworm-security/main arm\n",
      "\u001B[0m\u001B[2m => => # 64 Packages [98.6 kB]                                                 \n",
      "\u001B[0m\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 4.4s (14/18)                                  docker:desktop-linux\n",
      "\u001B[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 382B                                          0.0s\n",
      "\u001B[0m\u001B[34m => resolve image config for docker.io/docker/dockerfile:1                 0.7s\n",
      "\u001B[0m\u001B[34m => CACHED docker-image://docker.io/docker/dockerfile:1@sha256:ac85f380a6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load metadata for docker.io/library/python:3.11-slim        0.4s\n",
      "\u001B[0m\u001B[34m => [base 1/7] FROM docker.io/library/python:3.11-slim@sha256:f89d4d260b6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load build context                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 1.14kB                                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 2/7] WORKDIR /dependencies                                0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 3/7] RUN apt-get update -y &&     apt-get install -y --n  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 4/7] RUN if [ \"$(uname)\" = \"Linux\" ]; then     apt-get u  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 5/7] RUN python3 -m venv /opt/venv                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 6/7] COPY ./service_requirements.txt ./service_requireme  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 7/7] RUN pip install --no-cache -r service_requirements.  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [runtime 1/5] WORKDIR /service                                  0.0s\n",
      "\u001B[0m => [runtime 2/5] RUN apt-get update -y &&     apt-get install -y --no-in  3.2s\n",
      "\u001B[2m => => # Get:5 http://deb.debian.org/debian bookworm-updates/main arm64 Package\n",
      "\u001B[0m\u001B[2m => => # s [6672 B]                                                            \n",
      "\u001B[0m\u001B[2m => => # Get:6 http://deb.debian.org/debian-security bookworm-security/main arm\n",
      "\u001B[0m\u001B[2m => => # 64 Packages [98.6 kB]                                                 \n",
      "\u001B[0m\u001B[2m => => # Fetched 9037 kB in 3s (3043 kB/s)                                     \n",
      "\u001B[0m\u001B[2m => => # Reading package lists...                                              \n",
      "\u001B[0m\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 4.6s (14/18)                                  docker:desktop-linux\n",
      "\u001B[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 382B                                          0.0s\n",
      "\u001B[0m\u001B[34m => resolve image config for docker.io/docker/dockerfile:1                 0.7s\n",
      "\u001B[0m\u001B[34m => CACHED docker-image://docker.io/docker/dockerfile:1@sha256:ac85f380a6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load metadata for docker.io/library/python:3.11-slim        0.4s\n",
      "\u001B[0m\u001B[34m => [base 1/7] FROM docker.io/library/python:3.11-slim@sha256:f89d4d260b6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load build context                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 1.14kB                                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 2/7] WORKDIR /dependencies                                0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 3/7] RUN apt-get update -y &&     apt-get install -y --n  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 4/7] RUN if [ \"$(uname)\" = \"Linux\" ]; then     apt-get u  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 5/7] RUN python3 -m venv /opt/venv                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 6/7] COPY ./service_requirements.txt ./service_requireme  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 7/7] RUN pip install --no-cache -r service_requirements.  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [runtime 1/5] WORKDIR /service                                  0.0s\n",
      "\u001B[0m => [runtime 2/5] RUN apt-get update -y &&     apt-get install -y --no-in  3.4s\n",
      "\u001B[2m => => # Get:5 http://deb.debian.org/debian bookworm-updates/main arm64 Package\n",
      "\u001B[0m\u001B[2m => => # s [6672 B]                                                            \n",
      "\u001B[0m\u001B[2m => => # Get:6 http://deb.debian.org/debian-security bookworm-security/main arm\n",
      "\u001B[0m\u001B[2m => => # 64 Packages [98.6 kB]                                                 \n",
      "\u001B[0m\u001B[2m => => # Fetched 9037 kB in 3s (3043 kB/s)                                     \n",
      "\u001B[0m\u001B[2m => => # Reading package lists...                                              \n",
      "\u001B[0m\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 4.7s (14/18)                                  docker:desktop-linux\n",
      "\u001B[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 382B                                          0.0s\n",
      "\u001B[0m\u001B[34m => resolve image config for docker.io/docker/dockerfile:1                 0.7s\n",
      "\u001B[0m\u001B[34m => CACHED docker-image://docker.io/docker/dockerfile:1@sha256:ac85f380a6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load metadata for docker.io/library/python:3.11-slim        0.4s\n",
      "\u001B[0m\u001B[34m => [base 1/7] FROM docker.io/library/python:3.11-slim@sha256:f89d4d260b6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load build context                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 1.14kB                                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 2/7] WORKDIR /dependencies                                0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 3/7] RUN apt-get update -y &&     apt-get install -y --n  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 4/7] RUN if [ \"$(uname)\" = \"Linux\" ]; then     apt-get u  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 5/7] RUN python3 -m venv /opt/venv                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 6/7] COPY ./service_requirements.txt ./service_requireme  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 7/7] RUN pip install --no-cache -r service_requirements.  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [runtime 1/5] WORKDIR /service                                  0.0s\n",
      "\u001B[0m => [runtime 2/5] RUN apt-get update -y &&     apt-get install -y --no-in  3.5s\n",
      "\u001B[2m => => # s [6672 B]                                                            \n",
      "\u001B[0m\u001B[2m => => # Get:6 http://deb.debian.org/debian-security bookworm-security/main arm\n",
      "\u001B[0m\u001B[2m => => # 64 Packages [98.6 kB]                                                 \n",
      "\u001B[0m\u001B[2m => => # Fetched 9037 kB in 3s (3043 kB/s)                                     \n",
      "\u001B[0m\u001B[2m => => # Reading package lists...                                              \n",
      "\u001B[0m\u001B[2m => => # Reading package lists...                                              \n",
      "\u001B[0m\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 4.9s (14/18)                                  docker:desktop-linux\n",
      "\u001B[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 382B                                          0.0s\n",
      "\u001B[0m\u001B[34m => resolve image config for docker.io/docker/dockerfile:1                 0.7s\n",
      "\u001B[0m\u001B[34m => CACHED docker-image://docker.io/docker/dockerfile:1@sha256:ac85f380a6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load metadata for docker.io/library/python:3.11-slim        0.4s\n",
      "\u001B[0m\u001B[34m => [base 1/7] FROM docker.io/library/python:3.11-slim@sha256:f89d4d260b6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load build context                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 1.14kB                                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 2/7] WORKDIR /dependencies                                0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 3/7] RUN apt-get update -y &&     apt-get install -y --n  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 4/7] RUN if [ \"$(uname)\" = \"Linux\" ]; then     apt-get u  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 5/7] RUN python3 -m venv /opt/venv                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 6/7] COPY ./service_requirements.txt ./service_requireme  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 7/7] RUN pip install --no-cache -r service_requirements.  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [runtime 1/5] WORKDIR /service                                  0.0s\n",
      "\u001B[0m => [runtime 2/5] RUN apt-get update -y &&     apt-get install -y --no-in  3.7s\n",
      "\u001B[2m => => # s [6672 B]                                                            \n",
      "\u001B[0m\u001B[2m => => # Get:6 http://deb.debian.org/debian-security bookworm-security/main arm\n",
      "\u001B[0m\u001B[2m => => # 64 Packages [98.6 kB]                                                 \n",
      "\u001B[0m\u001B[2m => => # Fetched 9037 kB in 3s (3043 kB/s)                                     \n",
      "\u001B[0m\u001B[2m => => # Reading package lists...                                              \n",
      "\u001B[0m\u001B[2m => => # Reading package lists...                                              \n",
      "\u001B[0m\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 5.0s (14/18)                                  docker:desktop-linux\n",
      "\u001B[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 382B                                          0.0s\n",
      "\u001B[0m\u001B[34m => resolve image config for docker.io/docker/dockerfile:1                 0.7s\n",
      "\u001B[0m\u001B[34m => CACHED docker-image://docker.io/docker/dockerfile:1@sha256:ac85f380a6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load metadata for docker.io/library/python:3.11-slim        0.4s\n",
      "\u001B[0m\u001B[34m => [base 1/7] FROM docker.io/library/python:3.11-slim@sha256:f89d4d260b6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load build context                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 1.14kB                                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 2/7] WORKDIR /dependencies                                0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 3/7] RUN apt-get update -y &&     apt-get install -y --n  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 4/7] RUN if [ \"$(uname)\" = \"Linux\" ]; then     apt-get u  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 5/7] RUN python3 -m venv /opt/venv                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 6/7] COPY ./service_requirements.txt ./service_requireme  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 7/7] RUN pip install --no-cache -r service_requirements.  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [runtime 1/5] WORKDIR /service                                  0.0s\n",
      "\u001B[0m => [runtime 2/5] RUN apt-get update -y &&     apt-get install -y --no-in  3.8s\n",
      "\u001B[2m => => # 64 Packages [98.6 kB]                                                 \n",
      "\u001B[0m\u001B[2m => => # Fetched 9037 kB in 3s (3043 kB/s)                                     \n",
      "\u001B[0m\u001B[2m => => # Reading package lists...                                              \n",
      "\u001B[0m\u001B[2m => => # Reading package lists...                                              \n",
      "\u001B[0m\u001B[2m => => # Building dependency tree...                                           \n",
      "\u001B[0m\u001B[2m => => # Reading state information...                                          \n",
      "\u001B[0m\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 5.1s (15/18)                                  docker:desktop-linux\n",
      "\u001B[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001B[0m\u001B[34m => => transferring dockerfile: 2.07kB                                     0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 382B                                          0.0s\n",
      "\u001B[0m\u001B[34m => resolve image config for docker.io/docker/dockerfile:1                 0.7s\n",
      "\u001B[0m\u001B[34m => CACHED docker-image://docker.io/docker/dockerfile:1@sha256:ac85f380a6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load metadata for docker.io/library/python:3.11-slim        0.4s\n",
      "\u001B[0m\u001B[34m => [base 1/7] FROM docker.io/library/python:3.11-slim@sha256:f89d4d260b6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load build context                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 1.14kB                                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 2/7] WORKDIR /dependencies                                0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 3/7] RUN apt-get update -y &&     apt-get install -y --n  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 4/7] RUN if [ \"$(uname)\" = \"Linux\" ]; then     apt-get u  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 5/7] RUN python3 -m venv /opt/venv                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 6/7] COPY ./service_requirements.txt ./service_requireme  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 7/7] RUN pip install --no-cache -r service_requirements.  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [runtime 1/5] WORKDIR /service                                  0.0s\n",
      "\u001B[0m\u001B[34m => [runtime 2/5] RUN apt-get update -y &&     apt-get install -y --no-in  3.9s\n",
      "\u001B[0m                                                                                \n",
      "                                                                                \n",
      "                                                                                \n",
      "                                                                                \n",
      "\u001B[4A\u001B[0G\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 5.2s (15/18)                                  docker:desktop-linux\n",
      "\u001B[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001B[0m\u001B[34m => => transferring dockerfile: 2.07kB                                     0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 382B                                          0.0s\n",
      "\u001B[0m\u001B[34m => resolve image config for docker.io/docker/dockerfile:1                 0.7s\n",
      "\u001B[0m\u001B[34m => CACHED docker-image://docker.io/docker/dockerfile:1@sha256:ac85f380a6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load metadata for docker.io/library/python:3.11-slim        0.4s\n",
      "\u001B[0m\u001B[34m => [base 1/7] FROM docker.io/library/python:3.11-slim@sha256:f89d4d260b6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load build context                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 1.14kB                                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 2/7] WORKDIR /dependencies                                0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 3/7] RUN apt-get update -y &&     apt-get install -y --n  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 4/7] RUN if [ \"$(uname)\" = \"Linux\" ]; then     apt-get u  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 5/7] RUN python3 -m venv /opt/venv                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 6/7] COPY ./service_requirements.txt ./service_requireme  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 7/7] RUN pip install --no-cache -r service_requirements.  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [runtime 1/5] WORKDIR /service                                  0.0s\n",
      "\u001B[0m\u001B[34m => [runtime 2/5] RUN apt-get update -y &&     apt-get install -y --no-in  3.9s\n",
      "\u001B[0m => [runtime 3/5] COPY --from=base /opt/venv ./venv                        0.2s\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 5.4s (15/18)                                  docker:desktop-linux\n",
      "\u001B[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001B[0m\u001B[34m => => transferring dockerfile: 2.07kB                                     0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 382B                                          0.0s\n",
      "\u001B[0m\u001B[34m => resolve image config for docker.io/docker/dockerfile:1                 0.7s\n",
      "\u001B[0m\u001B[34m => CACHED docker-image://docker.io/docker/dockerfile:1@sha256:ac85f380a6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load metadata for docker.io/library/python:3.11-slim        0.4s\n",
      "\u001B[0m\u001B[34m => [base 1/7] FROM docker.io/library/python:3.11-slim@sha256:f89d4d260b6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load build context                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 1.14kB                                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 2/7] WORKDIR /dependencies                                0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 3/7] RUN apt-get update -y &&     apt-get install -y --n  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 4/7] RUN if [ \"$(uname)\" = \"Linux\" ]; then     apt-get u  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 5/7] RUN python3 -m venv /opt/venv                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 6/7] COPY ./service_requirements.txt ./service_requireme  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 7/7] RUN pip install --no-cache -r service_requirements.  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [runtime 1/5] WORKDIR /service                                  0.0s\n",
      "\u001B[0m\u001B[34m => [runtime 2/5] RUN apt-get update -y &&     apt-get install -y --no-in  3.9s\n",
      "\u001B[0m => [runtime 3/5] COPY --from=base /opt/venv ./venv                        0.3s\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 5.5s (15/18)                                  docker:desktop-linux\n",
      "\u001B[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001B[0m\u001B[34m => => transferring dockerfile: 2.07kB                                     0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 382B                                          0.0s\n",
      "\u001B[0m\u001B[34m => resolve image config for docker.io/docker/dockerfile:1                 0.7s\n",
      "\u001B[0m\u001B[34m => CACHED docker-image://docker.io/docker/dockerfile:1@sha256:ac85f380a6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load metadata for docker.io/library/python:3.11-slim        0.4s\n",
      "\u001B[0m\u001B[34m => [base 1/7] FROM docker.io/library/python:3.11-slim@sha256:f89d4d260b6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load build context                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 1.14kB                                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 2/7] WORKDIR /dependencies                                0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 3/7] RUN apt-get update -y &&     apt-get install -y --n  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 4/7] RUN if [ \"$(uname)\" = \"Linux\" ]; then     apt-get u  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 5/7] RUN python3 -m venv /opt/venv                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 6/7] COPY ./service_requirements.txt ./service_requireme  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 7/7] RUN pip install --no-cache -r service_requirements.  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [runtime 1/5] WORKDIR /service                                  0.0s\n",
      "\u001B[0m\u001B[34m => [runtime 2/5] RUN apt-get update -y &&     apt-get install -y --no-in  3.9s\n",
      "\u001B[0m => [runtime 3/5] COPY --from=base /opt/venv ./venv                        0.5s\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 5.7s (15/18)                                  docker:desktop-linux\n",
      "\u001B[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001B[0m\u001B[34m => => transferring dockerfile: 2.07kB                                     0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 382B                                          0.0s\n",
      "\u001B[0m\u001B[34m => resolve image config for docker.io/docker/dockerfile:1                 0.7s\n",
      "\u001B[0m\u001B[34m => CACHED docker-image://docker.io/docker/dockerfile:1@sha256:ac85f380a6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load metadata for docker.io/library/python:3.11-slim        0.4s\n",
      "\u001B[0m\u001B[34m => [base 1/7] FROM docker.io/library/python:3.11-slim@sha256:f89d4d260b6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load build context                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 1.14kB                                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 2/7] WORKDIR /dependencies                                0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 3/7] RUN apt-get update -y &&     apt-get install -y --n  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 4/7] RUN if [ \"$(uname)\" = \"Linux\" ]; then     apt-get u  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 5/7] RUN python3 -m venv /opt/venv                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 6/7] COPY ./service_requirements.txt ./service_requireme  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 7/7] RUN pip install --no-cache -r service_requirements.  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [runtime 1/5] WORKDIR /service                                  0.0s\n",
      "\u001B[0m\u001B[34m => [runtime 2/5] RUN apt-get update -y &&     apt-get install -y --no-in  3.9s\n",
      "\u001B[0m => [runtime 3/5] COPY --from=base /opt/venv ./venv                        0.6s\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 5.8s (15/18)                                  docker:desktop-linux\n",
      "\u001B[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001B[0m\u001B[34m => => transferring dockerfile: 2.07kB                                     0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 382B                                          0.0s\n",
      "\u001B[0m\u001B[34m => resolve image config for docker.io/docker/dockerfile:1                 0.7s\n",
      "\u001B[0m\u001B[34m => CACHED docker-image://docker.io/docker/dockerfile:1@sha256:ac85f380a6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load metadata for docker.io/library/python:3.11-slim        0.4s\n",
      "\u001B[0m\u001B[34m => [base 1/7] FROM docker.io/library/python:3.11-slim@sha256:f89d4d260b6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load build context                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 1.14kB                                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 2/7] WORKDIR /dependencies                                0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 3/7] RUN apt-get update -y &&     apt-get install -y --n  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 4/7] RUN if [ \"$(uname)\" = \"Linux\" ]; then     apt-get u  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 5/7] RUN python3 -m venv /opt/venv                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 6/7] COPY ./service_requirements.txt ./service_requireme  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 7/7] RUN pip install --no-cache -r service_requirements.  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [runtime 1/5] WORKDIR /service                                  0.0s\n",
      "\u001B[0m\u001B[34m => [runtime 2/5] RUN apt-get update -y &&     apt-get install -y --no-in  3.9s\n",
      "\u001B[0m => [runtime 3/5] COPY --from=base /opt/venv ./venv                        0.8s\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 6.0s (15/18)                                  docker:desktop-linux\n",
      "\u001B[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001B[0m\u001B[34m => => transferring dockerfile: 2.07kB                                     0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 382B                                          0.0s\n",
      "\u001B[0m\u001B[34m => resolve image config for docker.io/docker/dockerfile:1                 0.7s\n",
      "\u001B[0m\u001B[34m => CACHED docker-image://docker.io/docker/dockerfile:1@sha256:ac85f380a6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load metadata for docker.io/library/python:3.11-slim        0.4s\n",
      "\u001B[0m\u001B[34m => [base 1/7] FROM docker.io/library/python:3.11-slim@sha256:f89d4d260b6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load build context                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 1.14kB                                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 2/7] WORKDIR /dependencies                                0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 3/7] RUN apt-get update -y &&     apt-get install -y --n  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 4/7] RUN if [ \"$(uname)\" = \"Linux\" ]; then     apt-get u  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 5/7] RUN python3 -m venv /opt/venv                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 6/7] COPY ./service_requirements.txt ./service_requireme  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 7/7] RUN pip install --no-cache -r service_requirements.  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [runtime 1/5] WORKDIR /service                                  0.0s\n",
      "\u001B[0m\u001B[34m => [runtime 2/5] RUN apt-get update -y &&     apt-get install -y --no-in  3.9s\n",
      "\u001B[0m => [runtime 3/5] COPY --from=base /opt/venv ./venv                        0.9s\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 6.1s (15/18)                                  docker:desktop-linux\n",
      "\u001B[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001B[0m\u001B[34m => => transferring dockerfile: 2.07kB                                     0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 382B                                          0.0s\n",
      "\u001B[0m\u001B[34m => resolve image config for docker.io/docker/dockerfile:1                 0.7s\n",
      "\u001B[0m\u001B[34m => CACHED docker-image://docker.io/docker/dockerfile:1@sha256:ac85f380a6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load metadata for docker.io/library/python:3.11-slim        0.4s\n",
      "\u001B[0m\u001B[34m => [base 1/7] FROM docker.io/library/python:3.11-slim@sha256:f89d4d260b6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load build context                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 1.14kB                                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 2/7] WORKDIR /dependencies                                0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 3/7] RUN apt-get update -y &&     apt-get install -y --n  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 4/7] RUN if [ \"$(uname)\" = \"Linux\" ]; then     apt-get u  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 5/7] RUN python3 -m venv /opt/venv                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 6/7] COPY ./service_requirements.txt ./service_requireme  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 7/7] RUN pip install --no-cache -r service_requirements.  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [runtime 1/5] WORKDIR /service                                  0.0s\n",
      "\u001B[0m\u001B[34m => [runtime 2/5] RUN apt-get update -y &&     apt-get install -y --no-in  3.9s\n",
      "\u001B[0m => [runtime 3/5] COPY --from=base /opt/venv ./venv                        1.1s\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 6.3s (15/18)                                  docker:desktop-linux\n",
      "\u001B[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001B[0m\u001B[34m => => transferring dockerfile: 2.07kB                                     0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 382B                                          0.0s\n",
      "\u001B[0m\u001B[34m => resolve image config for docker.io/docker/dockerfile:1                 0.7s\n",
      "\u001B[0m\u001B[34m => CACHED docker-image://docker.io/docker/dockerfile:1@sha256:ac85f380a6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load metadata for docker.io/library/python:3.11-slim        0.4s\n",
      "\u001B[0m\u001B[34m => [base 1/7] FROM docker.io/library/python:3.11-slim@sha256:f89d4d260b6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load build context                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 1.14kB                                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 2/7] WORKDIR /dependencies                                0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 3/7] RUN apt-get update -y &&     apt-get install -y --n  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 4/7] RUN if [ \"$(uname)\" = \"Linux\" ]; then     apt-get u  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 5/7] RUN python3 -m venv /opt/venv                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 6/7] COPY ./service_requirements.txt ./service_requireme  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 7/7] RUN pip install --no-cache -r service_requirements.  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [runtime 1/5] WORKDIR /service                                  0.0s\n",
      "\u001B[0m\u001B[34m => [runtime 2/5] RUN apt-get update -y &&     apt-get install -y --no-in  3.9s\n",
      "\u001B[0m => [runtime 3/5] COPY --from=base /opt/venv ./venv                        1.2s\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 6.4s (18/19)                                  docker:desktop-linux\n",
      "\u001B[34m => => transferring dockerfile: 2.07kB                                     0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 382B                                          0.0s\n",
      "\u001B[0m\u001B[34m => resolve image config for docker.io/docker/dockerfile:1                 0.7s\n",
      "\u001B[0m\u001B[34m => CACHED docker-image://docker.io/docker/dockerfile:1@sha256:ac85f380a6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load metadata for docker.io/library/python:3.11-slim        0.4s\n",
      "\u001B[0m\u001B[34m => [base 1/7] FROM docker.io/library/python:3.11-slim@sha256:f89d4d260b6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load build context                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 1.14kB                                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 2/7] WORKDIR /dependencies                                0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 3/7] RUN apt-get update -y &&     apt-get install -y --n  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 4/7] RUN if [ \"$(uname)\" = \"Linux\" ]; then     apt-get u  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 5/7] RUN python3 -m venv /opt/venv                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 6/7] COPY ./service_requirements.txt ./service_requireme  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 7/7] RUN pip install --no-cache -r service_requirements.  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [runtime 1/5] WORKDIR /service                                  0.0s\n",
      "\u001B[0m\u001B[34m => [runtime 2/5] RUN apt-get update -y &&     apt-get install -y --no-in  3.9s\n",
      "\u001B[0m\u001B[34m => [runtime 3/5] COPY --from=base /opt/venv ./venv                        1.3s\n",
      "\u001B[0m\u001B[34m => [runtime 4/5] COPY ./ml_model_logging ./ml_model_logging               0.0s\n",
      "\u001B[0m\u001B[34m => [runtime 5/5] COPY ./LICENSE ./LICENSE                                 0.0s\n",
      "\u001B[0m => exporting to image                                                     0.1s\n",
      " => => exporting layers                                                    0.1s\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 6.6s (18/19)                                  docker:desktop-linux\n",
      "\u001B[34m => => transferring dockerfile: 2.07kB                                     0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 382B                                          0.0s\n",
      "\u001B[0m\u001B[34m => resolve image config for docker.io/docker/dockerfile:1                 0.7s\n",
      "\u001B[0m\u001B[34m => CACHED docker-image://docker.io/docker/dockerfile:1@sha256:ac85f380a6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load metadata for docker.io/library/python:3.11-slim        0.4s\n",
      "\u001B[0m\u001B[34m => [base 1/7] FROM docker.io/library/python:3.11-slim@sha256:f89d4d260b6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load build context                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 1.14kB                                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 2/7] WORKDIR /dependencies                                0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 3/7] RUN apt-get update -y &&     apt-get install -y --n  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 4/7] RUN if [ \"$(uname)\" = \"Linux\" ]; then     apt-get u  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 5/7] RUN python3 -m venv /opt/venv                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 6/7] COPY ./service_requirements.txt ./service_requireme  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 7/7] RUN pip install --no-cache -r service_requirements.  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [runtime 1/5] WORKDIR /service                                  0.0s\n",
      "\u001B[0m\u001B[34m => [runtime 2/5] RUN apt-get update -y &&     apt-get install -y --no-in  3.9s\n",
      "\u001B[0m\u001B[34m => [runtime 3/5] COPY --from=base /opt/venv ./venv                        1.3s\n",
      "\u001B[0m\u001B[34m => [runtime 4/5] COPY ./ml_model_logging ./ml_model_logging               0.0s\n",
      "\u001B[0m\u001B[34m => [runtime 5/5] COPY ./LICENSE ./LICENSE                                 0.0s\n",
      "\u001B[0m => exporting to image                                                     0.2s\n",
      " => => exporting layers                                                    0.2s\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 6.7s (18/19)                                  docker:desktop-linux\n",
      "\u001B[34m => => transferring dockerfile: 2.07kB                                     0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 382B                                          0.0s\n",
      "\u001B[0m\u001B[34m => resolve image config for docker.io/docker/dockerfile:1                 0.7s\n",
      "\u001B[0m\u001B[34m => CACHED docker-image://docker.io/docker/dockerfile:1@sha256:ac85f380a6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load metadata for docker.io/library/python:3.11-slim        0.4s\n",
      "\u001B[0m\u001B[34m => [base 1/7] FROM docker.io/library/python:3.11-slim@sha256:f89d4d260b6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load build context                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 1.14kB                                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 2/7] WORKDIR /dependencies                                0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 3/7] RUN apt-get update -y &&     apt-get install -y --n  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 4/7] RUN if [ \"$(uname)\" = \"Linux\" ]; then     apt-get u  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 5/7] RUN python3 -m venv /opt/venv                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 6/7] COPY ./service_requirements.txt ./service_requireme  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 7/7] RUN pip install --no-cache -r service_requirements.  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [runtime 1/5] WORKDIR /service                                  0.0s\n",
      "\u001B[0m\u001B[34m => [runtime 2/5] RUN apt-get update -y &&     apt-get install -y --no-in  3.9s\n",
      "\u001B[0m\u001B[34m => [runtime 3/5] COPY --from=base /opt/venv ./venv                        1.3s\n",
      "\u001B[0m\u001B[34m => [runtime 4/5] COPY ./ml_model_logging ./ml_model_logging               0.0s\n",
      "\u001B[0m\u001B[34m => [runtime 5/5] COPY ./LICENSE ./LICENSE                                 0.0s\n",
      "\u001B[0m => exporting to image                                                     0.4s\n",
      " => => exporting layers                                                    0.4s\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 6.9s (18/19)                                  docker:desktop-linux\n",
      "\u001B[34m => => transferring dockerfile: 2.07kB                                     0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 382B                                          0.0s\n",
      "\u001B[0m\u001B[34m => resolve image config for docker.io/docker/dockerfile:1                 0.7s\n",
      "\u001B[0m\u001B[34m => CACHED docker-image://docker.io/docker/dockerfile:1@sha256:ac85f380a6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load metadata for docker.io/library/python:3.11-slim        0.4s\n",
      "\u001B[0m\u001B[34m => [base 1/7] FROM docker.io/library/python:3.11-slim@sha256:f89d4d260b6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load build context                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 1.14kB                                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 2/7] WORKDIR /dependencies                                0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 3/7] RUN apt-get update -y &&     apt-get install -y --n  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 4/7] RUN if [ \"$(uname)\" = \"Linux\" ]; then     apt-get u  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 5/7] RUN python3 -m venv /opt/venv                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 6/7] COPY ./service_requirements.txt ./service_requireme  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 7/7] RUN pip install --no-cache -r service_requirements.  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [runtime 1/5] WORKDIR /service                                  0.0s\n",
      "\u001B[0m\u001B[34m => [runtime 2/5] RUN apt-get update -y &&     apt-get install -y --no-in  3.9s\n",
      "\u001B[0m\u001B[34m => [runtime 3/5] COPY --from=base /opt/venv ./venv                        1.3s\n",
      "\u001B[0m\u001B[34m => [runtime 4/5] COPY ./ml_model_logging ./ml_model_logging               0.0s\n",
      "\u001B[0m\u001B[34m => [runtime 5/5] COPY ./LICENSE ./LICENSE                                 0.0s\n",
      "\u001B[0m => exporting to image                                                     0.5s\n",
      " => => exporting layers                                                    0.5s\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 7.0s (18/19)                                  docker:desktop-linux\n",
      "\u001B[34m => => transferring dockerfile: 2.07kB                                     0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 382B                                          0.0s\n",
      "\u001B[0m\u001B[34m => resolve image config for docker.io/docker/dockerfile:1                 0.7s\n",
      "\u001B[0m\u001B[34m => CACHED docker-image://docker.io/docker/dockerfile:1@sha256:ac85f380a6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load metadata for docker.io/library/python:3.11-slim        0.4s\n",
      "\u001B[0m\u001B[34m => [base 1/7] FROM docker.io/library/python:3.11-slim@sha256:f89d4d260b6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load build context                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 1.14kB                                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 2/7] WORKDIR /dependencies                                0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 3/7] RUN apt-get update -y &&     apt-get install -y --n  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 4/7] RUN if [ \"$(uname)\" = \"Linux\" ]; then     apt-get u  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 5/7] RUN python3 -m venv /opt/venv                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 6/7] COPY ./service_requirements.txt ./service_requireme  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 7/7] RUN pip install --no-cache -r service_requirements.  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [runtime 1/5] WORKDIR /service                                  0.0s\n",
      "\u001B[0m\u001B[34m => [runtime 2/5] RUN apt-get update -y &&     apt-get install -y --no-in  3.9s\n",
      "\u001B[0m\u001B[34m => [runtime 3/5] COPY --from=base /opt/venv ./venv                        1.3s\n",
      "\u001B[0m\u001B[34m => [runtime 4/5] COPY ./ml_model_logging ./ml_model_logging               0.0s\n",
      "\u001B[0m\u001B[34m => [runtime 5/5] COPY ./LICENSE ./LICENSE                                 0.0s\n",
      "\u001B[0m => exporting to image                                                     0.7s\n",
      " => => exporting layers                                                    0.7s\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 7.2s (18/19)                                  docker:desktop-linux\n",
      "\u001B[34m => => transferring dockerfile: 2.07kB                                     0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 382B                                          0.0s\n",
      "\u001B[0m\u001B[34m => resolve image config for docker.io/docker/dockerfile:1                 0.7s\n",
      "\u001B[0m\u001B[34m => CACHED docker-image://docker.io/docker/dockerfile:1@sha256:ac85f380a6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load metadata for docker.io/library/python:3.11-slim        0.4s\n",
      "\u001B[0m\u001B[34m => [base 1/7] FROM docker.io/library/python:3.11-slim@sha256:f89d4d260b6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load build context                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 1.14kB                                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 2/7] WORKDIR /dependencies                                0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 3/7] RUN apt-get update -y &&     apt-get install -y --n  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 4/7] RUN if [ \"$(uname)\" = \"Linux\" ]; then     apt-get u  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 5/7] RUN python3 -m venv /opt/venv                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 6/7] COPY ./service_requirements.txt ./service_requireme  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 7/7] RUN pip install --no-cache -r service_requirements.  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [runtime 1/5] WORKDIR /service                                  0.0s\n",
      "\u001B[0m\u001B[34m => [runtime 2/5] RUN apt-get update -y &&     apt-get install -y --no-in  3.9s\n",
      "\u001B[0m\u001B[34m => [runtime 3/5] COPY --from=base /opt/venv ./venv                        1.3s\n",
      "\u001B[0m\u001B[34m => [runtime 4/5] COPY ./ml_model_logging ./ml_model_logging               0.0s\n",
      "\u001B[0m\u001B[34m => [runtime 5/5] COPY ./LICENSE ./LICENSE                                 0.0s\n",
      "\u001B[0m => exporting to image                                                     0.8s\n",
      " => => exporting layers                                                    0.8s\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 7.3s (18/19)                                  docker:desktop-linux\n",
      "\u001B[34m => => transferring dockerfile: 2.07kB                                     0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 382B                                          0.0s\n",
      "\u001B[0m\u001B[34m => resolve image config for docker.io/docker/dockerfile:1                 0.7s\n",
      "\u001B[0m\u001B[34m => CACHED docker-image://docker.io/docker/dockerfile:1@sha256:ac85f380a6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load metadata for docker.io/library/python:3.11-slim        0.4s\n",
      "\u001B[0m\u001B[34m => [base 1/7] FROM docker.io/library/python:3.11-slim@sha256:f89d4d260b6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load build context                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 1.14kB                                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 2/7] WORKDIR /dependencies                                0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 3/7] RUN apt-get update -y &&     apt-get install -y --n  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 4/7] RUN if [ \"$(uname)\" = \"Linux\" ]; then     apt-get u  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 5/7] RUN python3 -m venv /opt/venv                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 6/7] COPY ./service_requirements.txt ./service_requireme  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 7/7] RUN pip install --no-cache -r service_requirements.  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [runtime 1/5] WORKDIR /service                                  0.0s\n",
      "\u001B[0m\u001B[34m => [runtime 2/5] RUN apt-get update -y &&     apt-get install -y --no-in  3.9s\n",
      "\u001B[0m\u001B[34m => [runtime 3/5] COPY --from=base /opt/venv ./venv                        1.3s\n",
      "\u001B[0m\u001B[34m => [runtime 4/5] COPY ./ml_model_logging ./ml_model_logging               0.0s\n",
      "\u001B[0m\u001B[34m => [runtime 5/5] COPY ./LICENSE ./LICENSE                                 0.0s\n",
      "\u001B[0m => exporting to image                                                     1.0s\n",
      " => => exporting layers                                                    1.0s\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 7.5s (18/19)                                  docker:desktop-linux\n",
      "\u001B[34m => => transferring dockerfile: 2.07kB                                     0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 382B                                          0.0s\n",
      "\u001B[0m\u001B[34m => resolve image config for docker.io/docker/dockerfile:1                 0.7s\n",
      "\u001B[0m\u001B[34m => CACHED docker-image://docker.io/docker/dockerfile:1@sha256:ac85f380a6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load metadata for docker.io/library/python:3.11-slim        0.4s\n",
      "\u001B[0m\u001B[34m => [base 1/7] FROM docker.io/library/python:3.11-slim@sha256:f89d4d260b6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load build context                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 1.14kB                                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 2/7] WORKDIR /dependencies                                0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 3/7] RUN apt-get update -y &&     apt-get install -y --n  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 4/7] RUN if [ \"$(uname)\" = \"Linux\" ]; then     apt-get u  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 5/7] RUN python3 -m venv /opt/venv                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 6/7] COPY ./service_requirements.txt ./service_requireme  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 7/7] RUN pip install --no-cache -r service_requirements.  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [runtime 1/5] WORKDIR /service                                  0.0s\n",
      "\u001B[0m\u001B[34m => [runtime 2/5] RUN apt-get update -y &&     apt-get install -y --no-in  3.9s\n",
      "\u001B[0m\u001B[34m => [runtime 3/5] COPY --from=base /opt/venv ./venv                        1.3s\n",
      "\u001B[0m\u001B[34m => [runtime 4/5] COPY ./ml_model_logging ./ml_model_logging               0.0s\n",
      "\u001B[0m\u001B[34m => [runtime 5/5] COPY ./LICENSE ./LICENSE                                 0.0s\n",
      "\u001B[0m => exporting to image                                                     1.1s\n",
      "\u001B[34m => => exporting layers                                                    1.1s\n",
      "\u001B[0m\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 7.5s (19/19) FINISHED                         docker:desktop-linux\n",
      "\u001B[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001B[0m\u001B[34m => => transferring dockerfile: 2.07kB                                     0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 382B                                          0.0s\n",
      "\u001B[0m\u001B[34m => resolve image config for docker.io/docker/dockerfile:1                 0.7s\n",
      "\u001B[0m\u001B[34m => CACHED docker-image://docker.io/docker/dockerfile:1@sha256:ac85f380a6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load metadata for docker.io/library/python:3.11-slim        0.4s\n",
      "\u001B[0m\u001B[34m => [base 1/7] FROM docker.io/library/python:3.11-slim@sha256:f89d4d260b6  0.0s\n",
      "\u001B[0m\u001B[34m => [internal] load build context                                          0.0s\n",
      "\u001B[0m\u001B[34m => => transferring context: 1.14kB                                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 2/7] WORKDIR /dependencies                                0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 3/7] RUN apt-get update -y &&     apt-get install -y --n  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 4/7] RUN if [ \"$(uname)\" = \"Linux\" ]; then     apt-get u  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 5/7] RUN python3 -m venv /opt/venv                        0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 6/7] COPY ./service_requirements.txt ./service_requireme  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [base 7/7] RUN pip install --no-cache -r service_requirements.  0.0s\n",
      "\u001B[0m\u001B[34m => CACHED [runtime 1/5] WORKDIR /service                                  0.0s\n",
      "\u001B[0m\u001B[34m => [runtime 2/5] RUN apt-get update -y &&     apt-get install -y --no-in  3.9s\n",
      "\u001B[0m\u001B[34m => [runtime 3/5] COPY --from=base /opt/venv ./venv                        1.3s\n",
      "\u001B[0m\u001B[34m => [runtime 4/5] COPY ./ml_model_logging ./ml_model_logging               0.0s\n",
      "\u001B[0m\u001B[34m => [runtime 5/5] COPY ./LICENSE ./LICENSE                                 0.0s\n",
      "\u001B[0m\u001B[34m => exporting to image                                                     1.1s\n",
      "\u001B[0m\u001B[34m => => exporting layers                                                    1.1s\n",
      "\u001B[0m\u001B[34m => => writing image sha256:237e377147a425c0a313b8f90b4c21b806b2c9ccf922e  0.0s\n",
      "\u001B[0m\u001B[34m => => naming to docker.io/library/insurance_charges_model_service:0.1.0   0.0s\n",
      "\u001B[0m\u001B[?25h\u001B[1m\n",
      "What's Next?\n",
      "\u001B[0m  View a summary of image vulnerabilities and recommendations → \u001B[36mdocker scout quickview\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "!docker build \\\n",
    "  --build-arg DATE_CREATED=\"$DATE_CREATED\" \\\n",
    "  --build-arg VERSION=\"0.1.0\" \\\n",
    "  --build-arg REVISION=\"$REVISION\" \\\n",
    "  -t insurance_charges_model_service:0.1.0 ..\\"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc78b4c",
   "metadata": {},
   "source": [
    "To find the image we just built, we'll search through the local docker images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28b24a83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T19:29:59.144309Z",
     "start_time": "2023-11-18T19:29:58.887413Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "insurance_charges_model_service   0.1.0     237e377147a4   7 seconds ago    1.36GB\n"
     ]
    }
   ],
   "source": [
    "!docker images | grep insurance_charges_model_service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c3c4c1",
   "metadata": {},
   "source": [
    "Next, we'll start the image to see if everything is working as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f0dfd26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T19:30:12.373387Z",
     "start_time": "2023-11-18T19:30:07.116517Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docker: Error response from daemon: Conflict. The container name \"/insurance_charges_model_service\" is already in use by container \"de1210d55c048f648bc039fbf7bac3934c0257deeb3c63f13bba384f10824269\". You have to remove (or rename) that container to be able to reuse that name.\n",
      "See 'docker run --help'.\n"
     ]
    }
   ],
   "source": [
    "!docker run -d \\\n",
    "    -p 8000:8000 \\\n",
    "    -e REST_CONFIG=./configuration/rest_configuration.yaml \\\n",
    "    -e NODE_IP=\"123.123.123.123\" \\\n",
    "    -v $(pwd)/../configuration:/service/configuration \\\n",
    "    --name insurance_charges_model_service \\\n",
    "    insurance_charges_model_service:0.1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8aa9e6",
   "metadata": {},
   "source": [
    "Notice that we added an environment variable called NODE_IP, this is just so we have a value to pull into the logs later, its not the real node IP address.\n",
    "\n",
    "The service is up and running in the docker container. To view the logs coming out of the process, we'll use the docker logs command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9753c7c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T20:05:12.862684Z",
     "start_time": "2023-11-19T20:05:12.485163Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error response from daemon: No such container: de1210d55c048f648bc039fbf7bac3934c0257deeb3c63f13bba384f10824269\r\n"
     ]
    }
   ],
   "source": [
    "!docker logs insurance_charges_model_service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d208fc7e",
   "metadata": {},
   "source": [
    "As we expected, the logs are coming out in JSON format, although there are some that are not. These logs are being emitted from logger objects that were initialized before the rest_model_service package got a chance to be initialized.\n",
    "\n",
    "The service should be accessible on port 8000 of localhost, so we'll try to make a prediction using the curl command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "383b05c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T03:20:45.527311Z",
     "start_time": "2023-11-18T03:20:45.391925Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"detail\":\"Not Found\"}"
     ]
    }
   ],
   "source": [
    "!curl -X 'POST' \\\n",
    "  'http://127.0.0.1:8000/api/models/insurance_charges_model/prediction' \\\n",
    "  -H 'accept: application/json' \\\n",
    "  -H 'Content-Type: application/json' \\\n",
    "  -d '{ \\\n",
    "      \"age\": 53, \\\n",
    "      \"sex\": \"male\", \\\n",
    "      \"bmi\": 15, \\\n",
    "      \"children\": 0, \\\n",
    "      \"smoker\": True, \\\n",
    "      \"region\": \"southwest\", \\\n",
    "}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3879e0cd",
   "metadata": {},
   "source": [
    "We're done with the docker container so we'll stop it and stop it and remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df19cac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T03:16:55.971848Z",
     "start_time": "2023-11-18T03:16:55.643980Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error response from daemon: Cannot kill container: credit_risk_model_service: Container 3249c1fd36a1481ab8608e54717f3675d6b4af61b553c9c616d98b195e8e3fc4 is not running\r\n",
      "credit_risk_model_service\r\n"
     ]
    }
   ],
   "source": [
    "!docker kill insurance_charges_model_service\n",
    "!docker rm insurance_charges_model_service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf23128",
   "metadata": {},
   "source": [
    "## Creating a Kubernetes Cluster\n",
    "\n",
    "To show the system in action, we’ll deploy the model service and the minio service to a Kubernetes cluster. A local cluster can be easily started by using [minikube](https://minikube.sigs.k8s.io/docs/). Installation instructions can be found [here](https://minikube.sigs.k8s.io/docs/start/).\n",
    "\n",
    "To start the minikube cluster execute this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "70735cc4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T03:34:45.481648Z",
     "start_time": "2023-11-20T03:34:02.943127Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "😄  minikube v1.32.0 on Darwin 13.5 (arm64)\r\n",
      "✨  Using the docker driver based on existing profile\r\n",
      "💨  For improved Docker Desktop performance, Install the official release of Docker Desktop (Minimum recommended version is 20.10.0, minimum supported version is 18.09.0, current version is master)\r\n",
      "❗  docker is currently using the stargz storage driver, setting preload=false\r\n",
      "👍  Starting control plane node minikube in cluster minikube\r\n",
      "🚜  Pulling base image ...\r\n",
      "🏃  Updating the running docker \"minikube\" container ...\r\n",
      "🐳  Preparing Kubernetes v1.28.3 on Docker 24.0.7 ...\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\u001B[K\r\n",
      "🔎  Verifying Kubernetes components...\r\n",
      "    ▪ Using image gcr.io/k8s-minikube/storage-provisioner:v5\r\n",
      "🌟  Enabled addons: storage-provisioner, default-storageclass\r\n",
      "🏄  Done! kubectl is now configured to use \"minikube\" cluster and \"default\" namespace by default\r\n"
     ]
    }
   ],
   "source": [
    "!minikube start --memory 4196"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12798dc1",
   "metadata": {},
   "source": [
    "Let's view all of the pods running in the minikube cluster to make sure we can connect to it using the kubectl command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5cb90c7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T03:50:23.185700Z",
     "start_time": "2023-11-20T03:50:22.822872Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAMESPACE        NAME                                                  READY   STATUS              RESTARTS          AGE\r\n",
      "default          insurance-charges-model-deployment-65d4d4fd85-xztvj   0/1     ContainerCreating   0                 15h\r\n",
      "kube-system      coredns-5dd5756b68-rqslt                              1/1     Running             6 (16m ago)       30h\r\n",
      "kube-system      etcd-minikube                                         1/1     Running             5 (16m ago)       30h\r\n",
      "kube-system      kube-apiserver-minikube                               1/1     Running             5 (15m ago)       30h\r\n",
      "kube-system      kube-controller-manager-minikube                      1/1     Running             5 (16m ago)       30h\r\n",
      "kube-system      kube-proxy-pdk5h                                      1/1     Running             5 (16m ago)       30h\r\n",
      "kube-system      kube-scheduler-minikube                               1/1     Running             5 (16m ago)       30h\r\n",
      "kube-system      storage-provisioner                                   1/1     Running             10 (15m ago)      30h\r\n",
      "model-services   insurance-charges-model-deployment-54bf6b6884-hp9c4   0/1     ImagePullBackOff    0                 15h\r\n",
      "model-services   insurance-charges-model-deployment-65d4d4fd85-tsbms   0/1     Running             149 (5m31s ago)   15h\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get pods -A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d33987",
   "metadata": {},
   "source": [
    "Looks like we can connect, we're ready to start deploying the model service to the cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6bf08c",
   "metadata": {},
   "source": [
    "### Creating a Namespace\n",
    "\n",
    "Now that we have a cluster and are connected to it, we'll create a namespace to hold the resources for our model deployment. The resource definition is in the kubernetes/namespace.yaml file. To apply the manifest to the cluster, execute this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e7d2052f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T03:50:37.880381Z",
     "start_time": "2023-11-20T03:50:37.420995Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error from server (AlreadyExists): error when creating \"../kubernetes/namespace.yaml\": namespaces \"model-services\" already exists\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl create -f ../kubernetes/namespace.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963a64f4",
   "metadata": {},
   "source": [
    "To take a look at the namespaces, execute this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d93a5337",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T03:50:44.280505Z",
     "start_time": "2023-11-20T03:50:44.059173Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME              STATUS   AGE\r\n",
      "default           Active   30h\r\n",
      "kube-node-lease   Active   30h\r\n",
      "kube-public       Active   30h\r\n",
      "kube-system       Active   30h\r\n",
      "model-services    Active   16h\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get namespace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec0a472",
   "metadata": {},
   "source": [
    "The new namespace should appear in the listing along with other namespaces created by default by the system. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e92982",
   "metadata": {},
   "source": [
    "### Creating the Model Service\n",
    "\n",
    "The model service is deployed by using Kubernetes resources. These are:\n",
    "\n",
    "- ConfigMap: a set of configuration options, in this case it is a simple YAML file that will be loaded into the running container as a volume mount. This resource allows us to change the configuration of the model service without having to modify the Docker image.\n",
    "- Deployment: a declarative way to manage a set of Pods, the model service pods are managed through the Deployment.\n",
    "- Service: a way to expose a set of Pods in a Deployment, the model service is made available to the outside world through the Service.\n",
    "\n",
    "These resources are defined in the kubernetes/model_service.yaml file, the file is long so we won't list it here. The env section in the container's definition in the Deployment has a special section which is allowing us to access information about the pod and the node:\n",
    "\n",
    "```yaml\n",
    "...\n",
    "- name: REST_CONFIG\n",
    "  value: ./configuration/kubernetes_rest_config.yaml\n",
    "- name: POD_NAME\n",
    "  valueFrom:\n",
    "    fieldRef:\n",
    "      fieldPath: metadata.name\n",
    "- name: NODE_NAME\n",
    "  valueFrom:\n",
    "    fieldRef:\n",
    "      fieldPath: spec.nodeName\n",
    "- name: APP_NAME\n",
    "  valueFrom:\n",
    "    fieldRef:\n",
    "      fieldPath: metadata.labels['app']\n",
    "...\n",
    "```\n",
    "\n",
    "The pod definition is using the [downward API provided by Kubernetes](https://kubernetes.io/docs/tasks/inject-data-application/downward-api-volume-expose-pod-information/) to access the node name, the pod name, and the contents of the 'app' label. This information is made available as environment variables. We'll be adding this information to the log by adding the names of the environment variables to the logger configuration that we'll give to the model service. We built a logging context class above for the purpose of adding environment variables to log records.\n",
    "\n",
    "We're almost ready to deploy the model service, but before starting it we'll need to send the docker image from the local docker daemon to the minikube image cache:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3b4cd416",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T03:51:17.625027Z",
     "start_time": "2023-11-20T03:50:55.753523Z"
    }
   },
   "outputs": [],
   "source": [
    "!minikube image load insurance_charges_model_service:0.1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598e499d",
   "metadata": {},
   "source": [
    "We can view the images in the minikube cache with this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "753dacca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T03:52:12.561555Z",
     "start_time": "2023-11-20T03:52:11.410313Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docker.io/socratis01/insurance_charges_model_service:0.1.0\r\n",
      "docker.io/library/insurance_charges_model_service:0.1.0\r\n"
     ]
    }
   ],
   "source": [
    "!minikube image ls | grep insurance_charges_model_service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909afffb",
   "metadata": {},
   "source": [
    "The model service will need to access the YAML configuration file that we used for the local service above. This is file is in the /configuration folder and is called \"kubernetes_rest_config.yaml\", its customized for the kubernetes environment we're building.\n",
    "\n",
    "To create a [ConfigMap](https://kubernetes.io/docs/concepts/configuration/configmap/) for the service, execute this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9e86e74f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T03:53:06.775276Z",
     "start_time": "2023-11-20T03:53:06.554115Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "configmap/model-service-configuration created\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl create configmap -n model-services model-service-configuration \\\n",
    "    --from-file=../configuration/kubernetes_rest_config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146dda82",
   "metadata": {},
   "source": [
    "The service is deployed to the Kubernetes cluster with this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9fd4dee5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T03:53:13.615696Z",
     "start_time": "2023-11-20T03:53:13.188680Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment.apps/insurance-charges-model-deployment configured\r\n",
      "service/insurance-charges-model-service unchanged\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -n model-services -f ../kubernetes/model_service.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad273498",
   "metadata": {},
   "source": [
    "The deployment and service for the model service were created together. Lets view the Deployment to see if it is available yet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d680ae85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T03:53:40.862810Z",
     "start_time": "2023-11-20T03:53:40.424688Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                 READY   UP-TO-DATE   AVAILABLE   AGE\r\n",
      "insurance-charges-model-deployment   0/1     1            0           16h\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get deployments -n model-services "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be82f27",
   "metadata": {},
   "source": [
    "You can also view the pods that are running the service:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "aa3e77c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T03:54:19.505456Z",
     "start_time": "2023-11-20T03:54:19.157321Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                                  READY   STATUS             RESTARTS          AGE\r\n",
      "insurance-charges-model-deployment-54bf6b6884-hp9c4   0/1     ImagePullBackOff   0                 15h\r\n",
      "insurance-charges-model-deployment-65d4d4fd85-tsbms   0/1     CrashLoopBackOff   150 (2m27s ago)   15h\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get pods -n model-services -l app=insurance-charges-model-service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc80259",
   "metadata": {},
   "source": [
    "The Kubernetes Service details look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "91de8b20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T04:17:11.637188Z",
     "start_time": "2023-11-20T04:17:11.280104Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                              TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE\r\n",
      "insurance-charges-model-service   NodePort   10.108.77.253   <none>        80:32474/TCP   16h\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get services -n model-services "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b246e55",
   "metadata": {},
   "source": [
    "We'll run a proxy process locally to be able to access the model service endpoint:\n",
    "\n",
    "```bash\n",
    "minikube service credit-risk-model-service --url -n model-services\n",
    "```\n",
    "\n",
    "The command outputs this URL:\n",
    "\n",
    "http://127.0.0.1:50222\n",
    "\n",
    "We can send a request to the model service through the local endpoint like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3ff90ae9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T04:20:13.632850Z",
     "start_time": "2023-11-20T04:20:13.611569Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unmatched '}' (3807476846.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[61], line 2\u001B[0;36m\u001B[0m\n\u001B[0;31m    \"children\": 0, \"smoker\": true, \"region\": \"southwest\"}'\u001B[0m\n\u001B[0m                                                        ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m unmatched '}'\n"
     ]
    }
   ],
   "source": [
    "!curl -X 'POST' \\\n",
    "  'http://127.0.0.1:50222/api/models/credit_risk_model/prediction' \\\n",
    "  -H 'accept: application/json' \\\n",
    "  -H 'Content-Type: application/json' \\\n",
    "  -d '{ \\\n",
    "      \"annual_income\": 273000, \\\n",
    "      \"collections_in_last_12_months\": 20, \\\n",
    "      \"delinquencies_in_last_2_years\": 39, \\\n",
    "      \"debt_to_income_ratio\": 42.64, \\\n",
    "      \"employment_length\": \"< 1 year\", \\\n",
    "      \"home_ownership\": \"MORTGAGE\", \\\n",
    "      \"number_of_delinquent_accounts\": 6, \\\n",
    "      \"interest_rate\": 28.99, \\\n",
    "      \"last_payment_amount\": 36475.59, \\\n",
    "      \"loan_amount\": 35000, \\\n",
    "      \"derogatory_public_record_count\": 86, \\\n",
    "      \"loan_purpose\": \"debt_consolidation\", \\\n",
    "      \"revolving_line_utilization_rate\": 892.3, \\\n",
    "      \"term\": \" 36 months\", \\\n",
    "      \"total_payments_to_date\": 57777.58, \\\n",
    "      \"verification_status\": \"Source Verified\" \\\n",
    "}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace3d7c4",
   "metadata": {},
   "source": [
    "The model is deployed within Kubernetes!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae461e9c",
   "metadata": {},
   "source": [
    "### Accessing the Logs\n",
    "\n",
    "Kubernetes has a built-in system that receives the stdout and stderr outputs of the running containers and saves them to the hard drive of the node for a limited time. You can view the logs emitted by the containers by using this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9be87a45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T04:25:22.149367Z",
     "start_time": "2023-11-20T04:25:21.911350Z"
    }
   },
   "outputs": [],
   "source": [
    "!kubectl logs -n model-services insurance-charges-model-deployment-65d4d4fd85-tsbms -c insurance-charges-model | grep \"\\\"action\\\": \\\"predict\\\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d0ccc1",
   "metadata": {},
   "source": [
    "The logs contain every field that we configured and they are in JSON format, as we expected. The log records also contain the pod_name, node_name, and app_name fields that we added through the downward API.\n",
    "\n",
    "Although we can view the logs like this, this is not the ideal way to hold logs. We need to be able to search through the logs generated across the whole system. To do this we'll need to export the logs to an external logging system. We'll be working on that in another section of this blog post."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5254fc",
   "metadata": {},
   "source": [
    "## Creating the Logging System\n",
    "\n",
    "The complexity of modern cloud environment makes it hard to manage logs in individual servers since we really don't know where our workloads are going to be scheduled ahead of time. Kubernetes workloads are highly distributed, meaning that an application can be replicated in many different nodes in a cluster. This makes it necessary to gather logs together in one place so that we can more easily view and analyze them.\n",
    "\n",
    "A logging system is responsible for gathering  log records from all of the instances of a running application and make them searchable from one centralized location. In this section, we'll add such a logging system to the cluster and use it to monitor the model service we've deployed.\n",
    "\n",
    "We'll be installing the Elastic Cloud on Kubernetes operator in order to view our logs. The operator installs and manages ElasticSearch, Kibana, and Filebeat services.\n",
    "\n",
    "To begin, lets install the [custom resource definitions](https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/) needed by the operator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6fd2ec8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T04:25:30.344900Z",
     "start_time": "2023-11-20T04:25:28.858466Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customresourcedefinition.apiextensions.k8s.io/agents.agent.k8s.elastic.co created\r\n",
      "customresourcedefinition.apiextensions.k8s.io/apmservers.apm.k8s.elastic.co created\r\n",
      "customresourcedefinition.apiextensions.k8s.io/beats.beat.k8s.elastic.co created\r\n",
      "customresourcedefinition.apiextensions.k8s.io/elasticmapsservers.maps.k8s.elastic.co created\r\n",
      "customresourcedefinition.apiextensions.k8s.io/elasticsearchautoscalers.autoscaling.k8s.elastic.co created\r\n",
      "customresourcedefinition.apiextensions.k8s.io/elasticsearches.elasticsearch.k8s.elastic.co created\r\n",
      "customresourcedefinition.apiextensions.k8s.io/enterprisesearches.enterprisesearch.k8s.elastic.co created\r\n",
      "customresourcedefinition.apiextensions.k8s.io/kibanas.kibana.k8s.elastic.co created\r\n",
      "customresourcedefinition.apiextensions.k8s.io/stackconfigpolicies.stackconfigpolicy.k8s.elastic.co created\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl create -f https://download.elastic.co/downloads/eck/2.7.0/crds.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca2bdfc",
   "metadata": {},
   "source": [
    "We'll be using theses CRDs:\n",
    "\n",
    "- elasticsearch.k8s.elastic.co, to deploy ElasticSearch for storing and indexing logs\n",
    "- kibana.k8s.elastic.co, to deploy Kibana for viewing logs\n",
    "- beat.k8s.elastic.co, to deploy Filebeat on each node to forward logs to ElasticSearch\n",
    "\n",
    "The CRDs are used by the ECK operator to manage resources in the cluster. To install the ECK operator itself, execute this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e73f2145",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T04:26:08.030054Z",
     "start_time": "2023-11-20T04:26:06.622822Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "namespace/elastic-system created\r\n",
      "serviceaccount/elastic-operator created\r\n",
      "secret/elastic-webhook-server-cert created\r\n",
      "configmap/elastic-operator created\r\n",
      "clusterrole.rbac.authorization.k8s.io/elastic-operator created\r\n",
      "clusterrole.rbac.authorization.k8s.io/elastic-operator-view created\r\n",
      "clusterrole.rbac.authorization.k8s.io/elastic-operator-edit created\r\n",
      "clusterrolebinding.rbac.authorization.k8s.io/elastic-operator created\r\n",
      "service/elastic-webhook-server created\r\n",
      "statefulset.apps/elastic-operator created\r\n",
      "validatingwebhookconfiguration.admissionregistration.k8s.io/elastic-webhook.k8s.elastic.co created\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f https://download.elastic.co/downloads/eck/2.7.0/operator.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cf075d",
   "metadata": {},
   "source": [
    "### ElasticSearch \n",
    "\n",
    "We'll be storing logs in [ElasticSearch](https://www.elastic.co/elasticsearch/). ElasticSearch is a distributed full-text search engine with a RESTful API. The ElasticSearch service is ideal for our needs because our logs are made up of text strings.\n",
    "\n",
    "Now we're ready to install the service by applying the \"ElasticSearch\" custom resource definition:\n",
    "\n",
    "```yaml\n",
    "apiVersion: elasticsearch.k8s.elastic.co/v1\n",
    "kind: Elasticsearch\n",
    "metadata:\n",
    "  name: quickstart\n",
    "spec:\n",
    "  version: 8.7.0\n",
    "  nodeSets:\n",
    "  - name: default\n",
    "    count: 1\n",
    "    config:\n",
    "      node.store.allow_mmap: false\n",
    "```\n",
    "The CRD is stored in the kubernetes/elastic_search.yaml file. The CRD is applied with this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "21fc50aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T04:26:59.395264Z",
     "start_time": "2023-11-20T04:26:58.934491Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elasticsearch.elasticsearch.k8s.elastic.co/quickstart created\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -n elastic-system -f ../kubernetes/elastic_search.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c970559",
   "metadata": {},
   "source": [
    "To get a list of ElasticSearch clusters currently defined in the cluster, execute this comand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "57b1600d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T04:27:18.329853Z",
     "start_time": "2023-11-20T04:27:17.935697Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME         HEALTH    NODES   VERSION   PHASE             AGE\r\n",
      "quickstart   unknown           8.7.0     ApplyingChanges   19s\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get elasticsearch -n elastic-system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f85767",
   "metadata": {},
   "source": [
    "We can look at the pods running the ElasticSearch cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ad9d66e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T04:27:38.647083Z",
     "start_time": "2023-11-20T04:27:38.268444Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                      READY   STATUS    RESTARTS   AGE\r\n",
      "quickstart-es-default-0   0/1     Running   0          38s\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get pods -n elastic-system --selector='elasticsearch.k8s.elastic.co/cluster-name=quickstart'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8d21e5",
   "metadata": {},
   "source": [
    "A Kubernetes service is created to make the ElasticSearch service available to other services in the cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d8673167",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T04:28:00.305730Z",
     "start_time": "2023-11-20T04:27:59.974721Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                 TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE\r\n",
      "quickstart-es-http   ClusterIP   10.96.248.250   <none>        9200/TCP   61s\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get service quickstart-es-http -n elastic-system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd1cc12",
   "metadata": {},
   "source": [
    "A user named \"elastic\" is automatically in the ElasticSearch services with the password stored in a Kubernetes secret. Let's access the password:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "68ade75d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T04:28:06.613417Z",
     "start_time": "2023-11-20T04:28:06.356495Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zUS91mJo5Nki3It74aT4T183\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get secret quickstart-es-elastic-user -n elastic-system -o=jsonpath='{.data.elastic}' | base64 --decode; echo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4b0ee3",
   "metadata": {},
   "source": [
    "### Kibana\n",
    "\n",
    "To view the logs we'll be using [Kibana](https://www.elastic.co/kibana/). Kibana is a web application that can provide access to and visualize logs stored in ElasticSearch.\n",
    "\n",
    "The CRD for Kibana looks like this:\n",
    "\n",
    "```yaml\n",
    "apiVersion: kibana.k8s.elastic.co/v1\n",
    "kind: Kibana\n",
    "metadata:\n",
    "  name: quickstart\n",
    "spec:\n",
    "  version: 8.7.0\n",
    "  count: 1\n",
    "  elasticsearchRef:\n",
    "    name: quickstart\n",
    "```\n",
    "\n",
    "We'll apply the CRD with this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9397ee0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T04:29:25.637961Z",
     "start_time": "2023-11-20T04:29:25.207773Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kibana.kibana.k8s.elastic.co/quickstart created\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -n elastic-system -f ../kubernetes/kibana.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8827a8d9",
   "metadata": {},
   "source": [
    "Similar to Elasticsearch, you can retrieve details about Kibana instances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "58adf354",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T04:29:29.262565Z",
     "start_time": "2023-11-20T04:29:29.078227Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME         HEALTH   NODES   VERSION   AGE\r\n",
      "quickstart   red              8.7.0     4s\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get kibana -n elastic-system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb3d7a6",
   "metadata": {},
   "source": [
    "We can also view the associated Pods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686a2e2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T03:16:59.627256Z",
     "start_time": "2023-11-18T03:16:59.442327Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E1117 22:16:59.484674   18087 memcache.go:265] couldn't get current server API group list: Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "E1117 22:16:59.485097   18087 memcache.go:265] couldn't get current server API group list: Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "E1117 22:16:59.486251   18087 memcache.go:265] couldn't get current server API group list: Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "E1117 22:16:59.487262   18087 memcache.go:265] couldn't get current server API group list: Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "E1117 22:16:59.488501   18087 memcache.go:265] couldn't get current server API group list: Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "The connection to the server localhost:8080 was refused - did you specify the right host or port?\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get pod -n elastic-system --selector='kibana.k8s.elastic.co/name=quickstart'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4e99c4",
   "metadata": {},
   "source": [
    "A ClusterIP Service is automatically created for Kibana:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717b0b1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T03:16:59.833472Z",
     "start_time": "2023-11-18T03:16:59.604963Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E1117 22:16:59.719882   18088 memcache.go:265] couldn't get current server API group list: Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "E1117 22:16:59.721814   18088 memcache.go:265] couldn't get current server API group list: Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "E1117 22:16:59.722328   18088 memcache.go:265] couldn't get current server API group list: Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "E1117 22:16:59.723450   18088 memcache.go:265] couldn't get current server API group list: Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "E1117 22:16:59.724498   18088 memcache.go:265] couldn't get current server API group list: Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "The connection to the server localhost:8080 was refused - did you specify the right host or port?\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get service quickstart-kb-http -n elastic-system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6efbd2",
   "metadata": {},
   "source": [
    "We'll use kubectl port-forward to access Kibana from a local web browser:\n",
    "\n",
    "```bash\n",
    "kubectl port-forward service/quickstart-kb-http 5601 -n elastic-system\n",
    "```\n",
    "\n",
    "Now we can access the Kibana service from this URL:\n",
    "\n",
    "```\n",
    "http://localhost:5601\n",
    "```\n",
    "\n",
    "Open the URL in your browser to view the Kibana UI. Login as the \"elastic\" user. The password is the one we retrieved above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b57be1",
   "metadata": {},
   "source": [
    "### Filebeat\n",
    "\n",
    "In order to centralize access to logs, we'll first need a way to get the logs off of the individual cluster nodes and forward them to the aggregator service. The service we'll use to do this is called [Filebeat](https://www.elastic.co/beats/filebeat). Filebeat is a lightweight service that can forward logs stored in files to an outside service. We'll deploy Filebeat as a DaemonSet to ensure there’s a running instance on each node of the cluster.\n",
    "\n",
    "The Filebeat CRD looks like this:\n",
    "\n",
    "\n",
    "```yaml\n",
    "apiVersion: beat.k8s.elastic.co/v1beta1\n",
    "kind: Beat\n",
    "metadata:\n",
    "  name: quickstart\n",
    "spec:\n",
    "  type: filebeat\n",
    "  version: 8.7.0\n",
    "  elasticsearchRef:\n",
    "    name: quickstart\n",
    "  kibanaRef:\n",
    "    name: quickstart\n",
    "  config:\n",
    "    processors:\n",
    "      - decode_json_fields:\n",
    "          fields: [\"message\"]\n",
    "          max_depth: 3\n",
    "          target: parsed_message\n",
    "          add_error_key: false\n",
    "    filebeat.inputs:\n",
    "    - type: container\n",
    "      paths:\n",
    "      - /var/log/containers/*.log\n",
    "  daemonSet:\n",
    "    podTemplate:\n",
    "      spec:\n",
    "        dnsPolicy: ClusterFirstWithHostNet\n",
    "        hostNetwork: true\n",
    "        securityContext:\n",
    "          runAsUser: 0\n",
    "        containers:\n",
    "        - name: filebeat\n",
    "          volumeMounts:\n",
    "          - name: varlogcontainers\n",
    "            mountPath: /var/log/containers\n",
    "          - name: varlogpods\n",
    "            mountPath: /var/log/pods\n",
    "          - name: varlibdockercontainers\n",
    "            mountPath: /var/lib/docker/containers\n",
    "        volumes:\n",
    "        - name: varlogcontainers\n",
    "          hostPath:\n",
    "            path: /var/log/containers\n",
    "        - name: varlogpods\n",
    "          hostPath:\n",
    "            path: /var/log/pods\n",
    "        - name: varlibdockercontainers\n",
    "          hostPath:\n",
    "            path: /var/lib/docker/containers\n",
    "```\n",
    "\n",
    "The container logs host folder (/var/log/containers) is mounted on the Filebeat container. The filebeat process also has a processor defined:\n",
    "\n",
    "- decode_json_fields, which decodes fields containing JSON strings and replaces the strings with valid JSON objects\n",
    "\n",
    "Let's apply the CRD to create the Filebeat DaemonSet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250014d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T03:17:00.000421Z",
     "start_time": "2023-11-18T03:16:59.834368Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The connection to the server localhost:8080 was refused - did you specify the right host or port?\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -n elastic-system -f ../kubernetes/filebeat.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bd874a",
   "metadata": {},
   "source": [
    "Details about the Filebeat service can be viewed like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a29db6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T03:17:00.188117Z",
     "start_time": "2023-11-18T03:16:59.996031Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E1117 22:17:00.036754   18090 memcache.go:265] couldn't get current server API group list: Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "E1117 22:17:00.037460   18090 memcache.go:265] couldn't get current server API group list: Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "E1117 22:17:00.038310   18090 memcache.go:265] couldn't get current server API group list: Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "E1117 22:17:00.039394   18090 memcache.go:265] couldn't get current server API group list: Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "E1117 22:17:00.040641   18090 memcache.go:265] couldn't get current server API group list: Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "The connection to the server localhost:8080 was refused - did you specify the right host or port?\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get beat -n elastic-system "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d859d0b8",
   "metadata": {},
   "source": [
    "The pods running the service can be listed like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6eb37e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T03:17:00.337134Z",
     "start_time": "2023-11-18T03:17:00.180698Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E1117 22:17:00.224386   18091 memcache.go:265] couldn't get current server API group list: Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "E1117 22:17:00.225032   18091 memcache.go:265] couldn't get current server API group list: Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "E1117 22:17:00.226364   18091 memcache.go:265] couldn't get current server API group list: Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "E1117 22:17:00.227361   18091 memcache.go:265] couldn't get current server API group list: Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "E1117 22:17:00.229102   18091 memcache.go:265] couldn't get current server API group list: Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "The connection to the server localhost:8080 was refused - did you specify the right host or port?\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get pods -n elastic-system --selector='beat.k8s.elastic.co/name=quickstart'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb77d2df",
   "metadata": {},
   "source": [
    "The Filebeat service is running on the single node in the cluster.\n",
    "\n",
    "The logs are being forwarded to ElasticSearch and can be viewed in Kibana:\n",
    "\n",
    "![Prediction Log Stream](log_stream_lfmlm.png)\n",
    "![Prediction Log Stream]({attach}log_stream_lfmlm.png){ width=100% }\n",
    "\n",
    "We have logs arriving from the model service and can view them in Kibana!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b5bcfe",
   "metadata": {},
   "source": [
    "## Deleting the Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e9b6d3",
   "metadata": {},
   "source": [
    "To delete the Filebeat DaemonSet, execute this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91feb92b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T03:17:00.488580Z",
     "start_time": "2023-11-18T03:17:00.338178Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E1117 22:17:00.382700   18092 memcache.go:265] couldn't get current server API group list: Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "error: unable to recognize \"../kubernetes/filebeat.yaml\": Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete -n elastic-system -f ../kubernetes/filebeat.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19af9ed",
   "metadata": {},
   "source": [
    "To delete the Kibana service, execute this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87469759",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T03:17:00.639818Z",
     "start_time": "2023-11-18T03:17:00.489336Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E1117 22:17:00.534127   18094 memcache.go:265] couldn't get current server API group list: Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "error: unable to recognize \"../kubernetes/kibana.yaml\": Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete -n elastic-system -f ../kubernetes/kibana.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988494b4",
   "metadata": {},
   "source": [
    "To delete the ElasticSearch service, execute this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f00d72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T03:17:00.789373Z",
     "start_time": "2023-11-18T03:17:00.640569Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E1117 22:17:00.682625   18095 memcache.go:265] couldn't get current server API group list: Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "error: unable to recognize \"../kubernetes/elastic_search.yaml\": Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete -n elastic-system -f ../kubernetes/elastic_search.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322f0e6b",
   "metadata": {},
   "source": [
    "To remove all Elastic resources in all namespaces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3158bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T03:17:00.943687Z",
     "start_time": "2023-11-18T03:17:00.789853Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E1117 22:17:00.833377   18097 memcache.go:265] couldn't get current server API group list: Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "E1117 22:17:00.834082   18097 memcache.go:265] couldn't get current server API group list: Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "E1117 22:17:00.835670   18097 memcache.go:265] couldn't get current server API group list: Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "E1117 22:17:00.836398   18097 memcache.go:265] couldn't get current server API group list: Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "E1117 22:17:00.837459   18097 memcache.go:265] couldn't get current server API group list: Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "The connection to the server localhost:8080 was refused - did you specify the right host or port?\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get namespaces --no-headers -o custom-columns=:metadata.name | xargs -n1 kubectl delete elastic --all -n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c8b9ae",
   "metadata": {},
   "source": [
    "To uninstall the ECK operator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c0cd7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T03:17:01.502973Z",
     "start_time": "2023-11-18T03:17:00.944914Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E1117 22:17:01.383671   18099 memcache.go:265] couldn't get current server API group list: Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "E1117 22:17:01.384847   18099 memcache.go:265] couldn't get current server API group list: Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "E1117 22:17:01.385736   18099 memcache.go:265] couldn't get current server API group list: Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "E1117 22:17:01.386769   18099 memcache.go:265] couldn't get current server API group list: Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "E1117 22:17:01.389272   18099 memcache.go:265] couldn't get current server API group list: Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "E1117 22:17:01.389801   18099 memcache.go:265] couldn't get current server API group list: Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "E1117 22:17:01.390874   18099 memcache.go:265] couldn't get current server API group list: Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "E1117 22:17:01.391802   18099 memcache.go:265] couldn't get current server API group list: Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "E1117 22:17:01.392801   18099 memcache.go:265] couldn't get current server API group list: Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "E1117 22:17:01.393985   18099 memcache.go:265] couldn't get current server API group list: Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "E1117 22:17:01.395625   18099 memcache.go:265] couldn't get current server API group list: Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "unable to recognize \"https://download.elastic.co/downloads/eck/2.7.0/operator.yaml\": Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "unable to recognize \"https://download.elastic.co/downloads/eck/2.7.0/operator.yaml\": Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "unable to recognize \"https://download.elastic.co/downloads/eck/2.7.0/operator.yaml\": Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "unable to recognize \"https://download.elastic.co/downloads/eck/2.7.0/operator.yaml\": Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "unable to recognize \"https://download.elastic.co/downloads/eck/2.7.0/operator.yaml\": Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "unable to recognize \"https://download.elastic.co/downloads/eck/2.7.0/operator.yaml\": Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "unable to recognize \"https://download.elastic.co/downloads/eck/2.7.0/operator.yaml\": Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "unable to recognize \"https://download.elastic.co/downloads/eck/2.7.0/operator.yaml\": Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "unable to recognize \"https://download.elastic.co/downloads/eck/2.7.0/operator.yaml\": Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "unable to recognize \"https://download.elastic.co/downloads/eck/2.7.0/operator.yaml\": Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "unable to recognize \"https://download.elastic.co/downloads/eck/2.7.0/operator.yaml\": Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete -f https://download.elastic.co/downloads/eck/2.7.0/operator.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f7bff7",
   "metadata": {},
   "source": [
    "To uninstall the Custom Resource Definitions for the ECK operator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ba926f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T03:17:01.924408Z",
     "start_time": "2023-11-18T03:17:01.503875Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E1117 22:17:01.736311   18101 memcache.go:265] couldn't get current server API group list: Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "E1117 22:17:01.746253   18101 memcache.go:265] couldn't get current server API group list: Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "E1117 22:17:01.749795   18101 memcache.go:265] couldn't get current server API group list: Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "E1117 22:17:01.753278   18101 memcache.go:265] couldn't get current server API group list: Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "E1117 22:17:01.756110   18101 memcache.go:265] couldn't get current server API group list: Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "E1117 22:17:01.809537   18101 memcache.go:265] couldn't get current server API group list: Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "E1117 22:17:01.812907   18101 memcache.go:265] couldn't get current server API group list: Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "E1117 22:17:01.817762   18101 memcache.go:265] couldn't get current server API group list: Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "E1117 22:17:01.818940   18101 memcache.go:265] couldn't get current server API group list: Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "unable to recognize \"https://download.elastic.co/downloads/eck/2.7.0/crds.yaml\": Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "unable to recognize \"https://download.elastic.co/downloads/eck/2.7.0/crds.yaml\": Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "unable to recognize \"https://download.elastic.co/downloads/eck/2.7.0/crds.yaml\": Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "unable to recognize \"https://download.elastic.co/downloads/eck/2.7.0/crds.yaml\": Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "unable to recognize \"https://download.elastic.co/downloads/eck/2.7.0/crds.yaml\": Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "unable to recognize \"https://download.elastic.co/downloads/eck/2.7.0/crds.yaml\": Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "unable to recognize \"https://download.elastic.co/downloads/eck/2.7.0/crds.yaml\": Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "unable to recognize \"https://download.elastic.co/downloads/eck/2.7.0/crds.yaml\": Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "unable to recognize \"https://download.elastic.co/downloads/eck/2.7.0/crds.yaml\": Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete -f https://download.elastic.co/downloads/eck/2.7.0/crds.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78903c33",
   "metadata": {},
   "source": [
    "To delete the model service kubernetes resources, we'll execute this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2825ed48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T03:17:02.073318Z",
     "start_time": "2023-11-18T03:17:01.928342Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E1117 22:17:01.965535   18105 memcache.go:265] couldn't get current server API group list: Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "E1117 22:17:01.967253   18105 memcache.go:265] couldn't get current server API group list: Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "unable to recognize \"../kubernetes/model_service.yaml\": Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "unable to recognize \"../kubernetes/model_service.yaml\": Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete -n model-services -f ../kubernetes/model_service.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc5b517",
   "metadata": {},
   "source": [
    "We'll also delete the ConfigMap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dde64ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T03:17:02.226208Z",
     "start_time": "2023-11-18T03:17:02.073759Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E1117 22:17:02.117272   18107 memcache.go:265] couldn't get current server API group list: Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "E1117 22:17:02.117875   18107 memcache.go:265] couldn't get current server API group list: Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "E1117 22:17:02.119045   18107 memcache.go:265] couldn't get current server API group list: Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "E1117 22:17:02.120012   18107 memcache.go:265] couldn't get current server API group list: Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "E1117 22:17:02.121024   18107 memcache.go:265] couldn't get current server API group list: Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "The connection to the server localhost:8080 was refused - did you specify the right host or port?\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete -n model-services configmap model-service-configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f64c43",
   "metadata": {},
   "source": [
    "Then the model service namespace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5186f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T03:17:02.375606Z",
     "start_time": "2023-11-18T03:17:02.226407Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E1117 22:17:02.269287   18108 memcache.go:265] couldn't get current server API group list: Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n",
      "error: unable to recognize \"../kubernetes/namespace.yaml\": Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete -f ../kubernetes/namespace.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0ae158",
   "metadata": {},
   "source": [
    "To shut down the minikube cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53f2120",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T03:17:02.493277Z",
     "start_time": "2023-11-18T03:17:02.376868Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: minikube\r\n"
     ]
    }
   ],
   "source": [
    "!minikube stop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb52f6a0",
   "metadata": {},
   "source": [
    "## Closing\n",
    "\n",
    "In this blog post we showed how to do logging with the Python logging package, and how to create a decorator that can help us to do logging around an MLModel instance. We also set up and used a logging system within a Kubernetes cluster and used it to aggregate logs and view them. Logging is usually the first thing that is implemented when we need to monitor how a system performs, and machine learning models are no exception to this. The logging decorator allowed us to do complex logging without having to modify the implementation of the model at all, thus simplifying a common aspect of software observability.\n",
    "\n",
    "One of the benefits of using the decorator pattern is that we are able to build up complex behaviors around an object. The LoggingDecorator class is very configurable, since we are able to configure it to log input and output fields from the model. This approach makes the implementation very flexible, since we do not need to modify the decorator's code to add fields to the log. The EnvironmentInfoFilter class that we implemented to grab information from the environment for logs is also built this way. We were able to get information about the Kubernetes deployment from the logs without having to modify the code.\n",
    "\n",
    "The LoggingDecorator class is designed to work with MLModel classes, and this is the only hard requirement of the code. This makes the decorator very portable, because we are able to deploy it inside of any other model deployment service we may choose to build in the future. For example, we can just as easily decorate an MLModel instance running inside of an gRPC service, since the decorator would work exactly the same way. This is due to interface-driven approach that we took when designing the MLModel interface.\n",
    "\n",
    "We added logging to the ML model instance from the \"outside\" and we were not able to access information about the internals of the model. This is a limitation of the decorator approach to logging which only has access to the model inputs, model outputs, and exceptions raised by the model. This approach is best used to add logging functionality to an ML model implementation that we do not control, or in simple situations in which the limitations of the approach do not affect us. If any logging of internal model state is needed, we'll need to generate logs from within the MLModel class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a7740f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T03:17:02.497762Z",
     "start_time": "2023-11-18T03:17:02.493199Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
